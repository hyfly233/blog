Doris 3.0 开始支持存算分离

## 存算一体 VS 存算分离

Doris 的整体架构由两类进程组成：Frontend (FE) 和 Backend (BE)。其中 FE 主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理相关工作；BE 主要负责数据存储、查询计划的执行

### 存算一体

在存算一体架构下，BE 节点上存储与计算紧密耦合，数据主要存储在 BE 节点上，多 BE 节点采用 MPP 分布式计算架构

### 存算分离

BE 节点不再存储主数据，而是将共享存储层作为统一的数据主存储空间。同时，为了应对底层对象存储系统性能不佳和网络传输带来的性能下降，Doris 引入计算节点本地高速缓存

**元数据层：**

FE 主要存放库表元数据，Job 以及权限等 MySQL 协议依赖的信息。

Meta Service 是 Doris 存算分离元数据服务，主要负责处理导入事务，Tablet Meta，Rowset Meta 以及集群资源管理。这是一个可以横向扩展的无状态服务。

**计算层：**

存算分离模式下的 BE 是无状态的 Doris BE 节点，BE 上会缓存一部分 Tablet 元数据和数据以提高查询性能。

计算集群（Compute Cluster）是无状态的 BE 节点组成的计算资源集合，多个计算集群共享一份数据，计算集群可以随时弹性加减节点。

备注

存算分离文档中的“计算集群”概念有别于 Doris【集群部署】以及后文【创建集群】中的“集群”概念。存算分离文档中提及的“计算集群”特指在 Doris 存算分离模式下，由无状态 BE 节点组成的计算资源集合，而非【集群部署】和【创建集群】中所指的由多个 Apache Doris 节点组成的完整分布式系统。

**共享存储层：**

共享存储主要存放数据文件，包括 Segment 文件、反向索引的索引文件等。

## 如何选择

### 存算一体的优点

- 部署简易：Apache Doris 不需要依赖类似外部共享文件系统或者对象存储，仅依赖物理服务器部署 FE 和 BE 两个进程即可完成集群的搭建，可以从一个节点扩展到数百个节点，同时也增强了系统的稳定性。
- 性能优异：Apache Doris 执行计算时，计算节点可直接访问本地存储数据，充分利用机器的 IO、减少不必要的网络开销、获得更极致的查询性能。

### **存算一体的**适用场景

- 简单使用/快速试用 Doris，或在开发和测试环境中使用；
- 不具备可靠的共享存储，如 HDFS、Ceph、对象存储等；
- 业务线独立维护 Apache Doris，无专职 DBA 来维护 Doris 集群；
- 不需极致弹性扩缩容，不需 K8s 容器化，不需运行在公有云或者私有云上。

### 存算分离的优点

- 弹性的计算资源：不同时间点使用不同规模的计算资源服务业务请求，按需使用计算资源，节约成本。
- 负载（完全）隔离：不同业务之间可在共享数据的基础上隔离计算资源，兼具稳定性和高效率。
- 低存储成本：可以使用更低成本的对象存储，HDFS 等低成本存储。

### **存算分离的**适用场景

- 已使用公有云服务
- 具备可靠的共享存储系统，比如 HDFS、Ceph、对象存储等
- 需要极致的弹性扩缩容，需要 K8S 容器化，需要运行在私有云上
- 有专职团队维护整个公司的数据仓库平台



# Doris 存算分离模式部署准备

## 1. 概述

本文档介绍了 Apache Doris 存算分离模式的部署准备工作。存算分离架构旨在提高系统的可扩展性和性能，适用于大规模数据处理场景。

## 2. 架构组件

Doris 存算分离架构包含三个主要模块：

1. **Frontend (FE)**：处理用户请求和管理元数据。
2. **Backend (BE)**：无状态计算节点，执行查询任务。
3. **Meta Service (MS)**：管理元数据操作和数据回收。

## 3. 系统要求

### 3.1 硬件要求

- 最小配置：3 台服务器
- 推荐配置：5 台或更多服务器

### 3.2 软件依赖

- FoundationDB (FDB) 7.1.38 或更高版本
- OpenJDK 17

## 4. 部署规划

### 4.1 测试环境部署

单机部署所有模块，不适用于生产环境。

### 4.2 生产部署

- 3 台或更多机器部署 FDB
- 3 台或更多机器部署 FE 和 Meta Service
- 3 台或更多机器部署 BE

机器配置高时，可以考虑 FDB、FE 和 Meta Service 混布，但是磁盘不要混用。

## 5. 安装步骤

### 5.1 安装 FoundationDB

本节提供了脚本 `fdb_vars.sh` 和 `fdb_ctl.sh` 配置、部署和启动 FDB（FoundationDB）服务的分步指南。您可以下载 [doris tools](http://apache-doris-releases.oss-accelerate.aliyuncs.com/apache-doris-3.0.2-tools.tar.gz) 并从 `fdb` 目录获取 `fdb_vars.sh` 和 `fdb_ctl.sh`。

#### 5.1.1 机器要求

通常，至少需要 3 台配备 SSD 的机器来形成具有双数据副本并允许单机故障的 FoundationDB 集群。

提示

如果仅用于开发/测试目的，单台机器就足够了。

#### 5.1.2 `fdb_vars.sh` 配置

##### 必需的自定义设置

| 参数               | 描述                             | 类型                           | 示例                                                         | 注意事项                                                     |
| ------------------ | -------------------------------- | ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| `DATA_DIRS`        | 指定 FoundationDB 存储的数据目录 | 以逗号分隔的绝对路径列表       | `/mnt/foundationdb/data1,/mnt/foundationdb/data2,/mnt/foundationdb/data3` | - 运行脚本前确保目录已创建 - 生产环境建议使用 SSD 和独立目录 |
| `FDB_CLUSTER_IPS`  | 定义集群 IP                      | 字符串（以逗号分隔的 IP 地址） | `172.200.0.2,172.200.0.3,172.200.0.4`                        | - 生产集群至少应有 3 个 IP 地址 - 第一个 IP 地址将用作协调器 - 为高可用性，将机器放置在不同机架上 |
| `FDB_HOME`         | 定义 FoundationDB 主目录         | 绝对路径                       | `/fdbhome`                                                   | - 默认路径为 /fdbhome - 确保此路径是绝对路径                 |
| `FDB_CLUSTER_ID`   | 定义集群 ID                      | 字符串                         | `SAQESzbh`                                                   | - 每个集群的 ID 必须唯一 - 可使用 `mktemp -u XXXXXXXX` 生成  |
| `FDB_CLUSTER_DESC` | 定义 FDB 集群的描述              | 字符串                         | `dorisfdb`                                                   | - 建议更改为对部署有意义的内容                               |

##### 可选的自定义设置

| 参数              | 描述                               | 类型 | 示例                 | 注意事项                                         |
| ----------------- | ---------------------------------- | ---- | -------------------- | ------------------------------------------------ |
| `MEMORY_LIMIT_GB` | 定义 FDB 进程的内存限制，单位为 GB | 整数 | `MEMORY_LIMIT_GB=16` | 根据可用内存资源和 FDB 进程的要求调整此值        |
| `CPU_CORES_LIMIT` | 定义 FDB 进程的 CPU 核心限制       | 整数 | `CPU_CORES_LIMIT=8`  | 根据可用的 CPU 核心数量和 FDB 进程的要求设置此值 |

#### 5.1.3 部署 FDB 集群

使用 `fdb_vars.sh` 配置环境后，您可以在每个节点上使用 `fdb_ctl.sh` 脚本部署 FDB 集群。

```bash
./fdb_ctl.sh deploy
```



此命令启动 FDB 集群的部署过程。

#### 5.1.4 启动 FDB 服务

FDB 集群部署完成后，您可以使用 `fdb_ctl.sh` 脚本启动 FDB 服务。

```bash
./fdb_ctl.sh start
```



此命令启动 FDB 服务，使集群工作并获取 FDB 集群连接字符串，后续可以用于配置 MetaService。

### 5.2 安装 OpenJDK 17

1. 下载 [OpenJDK 17](https://download.java.net/java/GA/jdk17.0.1/2a2082e5a09d4267845be086888add4f/12/GPL/openjdk-17.0.1_linux-x64_bin.tar.gz)
2. 解压并设置环境变量 JAVA_HOME.

### 5.3 安装 S3 或 HDFS 服务（可选）

Apache Doris 存算分离模式会将数据存储在 S3 服务或 HDFS 服务上面，如果您已经有相关服务，直接使用即可。如果没有，本文档提供 MinIO 的简单部署教程：

1. 在 MinIO 的[下载页面](https://min.io/download?license=agpl&platform=linux)选择合适的版本以及操作系统，下载对应的 Server 以及 Client 的二进制包或安装包。

2. 启动 MinIO Server

   ```bash
   export MINIO_REGION_NAME=us-east-1
   export MINIO_ROOT_USER=minio # 在较老版本中，该配置为 MINIO_ACCESS_KEY=minio
   export MINIO_ROOT_PASSWORD=minioadmin # 在较老版本中，该配置为 MINIO_SECRET_KEY=minioadmin
   nohup ./minio server /mnt/data 2>&1 &
   ```

   

3. 配置 MinIO Client

   ```bash
   # 如果你使用的是安装包安装的客户端，那么客户端名为 mcli，直接下载客户端二进制包，则其名为 mc
   ./mc config host add myminio http://127.0.0.1:9000 minio minioadmin
   ```

   

4. 创建一个桶

   ```bash
   ./mc mb myminio/doris
   ```

   

5. 验证是否正常工作

   ```bash
   # 上传一个文件
   ./mc mv test_file myminio/doris
   # 查看这个文件
   ./mc ls myminio/doris
   ```

   

## 7. 注意事项

- 确保所有节点的时间同步
- 定期备份 FoundationDB 数据
- 根据实际负载调整 FoundationDB 和 Doris 的配置参数



# 编译部署



## 2. 获取二进制

### 2.1 直接下载

已编译好的二进制文件（包含所有 Doris 模块）可从 [Doris 下载页面](https://doris.apache.org/download/) 获取（选择 3.0.2 或更高版本）。

### 2.2 编译产出 (可选)

使用代码库自带的 `build.sh` 脚本进行编译。新增的 MS 模块通过 `--cloud` 参数编译。

```shell
sh build.sh --fe --be --cloud 
```



编译完成后，在 `output` 目录下会新增 `ms` 目录：

```text
output
├── be
├── fe
└── ms
    ├── bin
    ├── conf
    └── lib
```



## 3. Meta Service 部署

### 3.1 配置

在 `./conf/doris_cloud.conf` 文件中，主要需要修改以下两个参数：

1. `brpc_listen_port`：Meta Service 的监听端口，默认为 5000。
2. `fdb_cluster`：FoundationDB 集群的连接信息，部署 FoundationDB 时可以获取。(如果使用 Doris 提供的 fdb_ctl.sh 部署的话，可在 `$FDB_HOME/conf/fdb.cluster` 文件里获取该值)。

示例配置：

```shell
brpc_listen_port = 5000
fdb_cluster = xxx:yyy@127.0.0.1:4500
```



注意：`fdb_cluster` 的值应与 FoundationDB 部署机器上的 `/etc/foundationdb/fdb.cluster` 文件内容一致 (如果使用 Doris 提供的 fdb_ctl.sh 部署的话，可在 `$FDB_HOME/conf/fdb.cluster` 文件里获取该值)。

**示例，文件的最后一行就是要填到 doris_cloud.conf 里 fdb_cluster 字段的值**

```shell
cat /etc/foundationdb/fdb.cluster

# DO NOT EDIT!
# This file is auto-generated, it is not to be edited by hand.
cloud_ssb:A83c8Y1S3ZbqHLL4P4HHNTTw0A83CuHj@127.0.0.1:4500
```



### 3.2 启动与停止

*环境要求*

确保已正确设置 `JAVA_HOME` 环境变量，指向 OpenJDK 17，进入 `ms` 目录。

*启动命令*

```shell
export JAVA_HOME=${path_to_jdk_17}
bin/start.sh --daemon
```



```text
LIBHDFS3_CONF=
starts doris_cloud with args: --meta-service
wait and check doris_cloud start successfully
successfully started brpc listening on port=5000 time_elapsed_ms=11
doris_cloud start successfully
```



启动脚本返回值为 0 表示启动成功，否则启动失败。

信息

在 3.0.4 中，启动脚本会输出更多信息：

```text
2024-12-26 15:31:53 start with args: --meta-service
wait and check MetaService and Recycler start successfully
process working directory: "/mnt/disk1/doris/ms"
pid=1666015 written to file=./bin/doris_cloud.pid
version:{doris-3.0.4-release} code_version:{commit=fd44740fadabebfedb5da201d7ce427a5dd47c44 time=2025-01-16 18:53:00 +0800} build_info: ...

MetaService has been started successfully
successfully started service listening on port=5000 time_elapsed_ms=19
```



*停止命令*

```shell
bin/stop.sh
```



生产环境中请确保至少有 3 个 Meta Service 节点。

## 4. 数据回收功能独立部署（可选）

信息

Meta Service 本身具备了元数据管理和回收功能，这两个功能可以独立部署，如果你想独立部署，可以参考这一节。

*准备工作*

1. 创建新的工作目录（如 `recycler`）。

2. 复制 `ms` 目录内容到新目录：

   ```shell
   cp -r ms recycler
   ```

   

*配置*

在新目录的配置文件中修改 BRPC 监听端口 `brpc_listen_port` 和 `fdb_cluster` 的值。

*启动数据回收功能*

```shell
export JAVA_HOME=${path_to_jdk_17}
bin/start.sh --recycler --daemon
```



*启动仅元数据操作功能*

```shell
export JAVA_HOME=${path_to_jdk_17}
bin/start.sh --meta-service --daemon
```



## 5. FE 和 BE 的启动流程

本节详细说明了在存算分离架构下启动 FE（Frontend）和 BE（Backend）的步骤。

### 5.1 启动顺序

1. 以 MASTER 角色启动实例的第一个 FE
2. 向实例中添加其他 FE 和 BE
3. 添加第一个 Storage Vault

### 5.2 启动 MASTER 角色的 FE

#### 5.2.1 配置 fe.conf

在 `fe.conf` 文件中，需要配置以下关键参数：

1. `deploy_mode`

   - 描述：指定 doris 启动模式
   - 格式：cloud 表示存算分离模式，其它存算一体模式
   - 示例：`cloud`

2. `cluster_id`

   - 描述：存算分离架构下集群的唯一标识符，不同的集群必须设置不同的 cluster_id

   - 格式：int 类型

   - 示例：可以使用如下 shell 脚本生成一个随机 id 使用。

     ```shell
     echo $(($((RANDOM << 15)) | $RANDOM))
     ```

     

     警告

     **不同的集群必须设置不同的 cluster_id**

3. `meta_service_endpoint`

   - 描述：Meta Service 的地址和端口
   - 格式：`IP地址:端口号`
   - 示例：`127.0.0.1:5000`, 可以用逗号分割配置多个 meta service。

#### 5.2.2 启动 FE

启动命令示例：

```bash
bin/start_fe.sh --daemon
```



第一个 FE 进程初始化集群并以 FOLLOWER 角色工作。使用 mysql 客户端连接 FE 使用 `show frontends` 确认刚才启动的 FE 是 master。

### 5.3 添加其他 FE 节点

其他节点同样根据上述步骤修改配置文件并启动，使用 mysql 客户端连接 Master 角色的 FE，并用以下 SQL 命令添加额外的 FE 节点：

```sql
ALTER SYSTEM ADD FOLLOWER "host:port";
```



将 `host:port` 替换为 FE 节点的实际地址和编辑日志端口。更多信息请参见 [ADD FOLLOWER](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/instance-management/ADD-FOLLOWER) 和 [ADD OBSERVER](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/instance-management/ADD-OBSERVER)。

生产环境中请确保在 FOLLOWER 角色中的前端 (FE) 节点总数，包括第一个 FE，保持为奇数。一般来说，三个 FOLLOWER 就足够了。OBSERVER 角色的前端节点可以是任意数量。

### 5.4 添加 BE 节点

要向集群添加 Backend 节点，请对每个 Backend 执行以下步骤：

#### 5.4.1 配置 be.conf

在 `be.conf` 文件中，需要配置以下关键参数：

1. `deploy_mode`
   - 描述：指定 doris 启动模式
   - 格式：cloud 表示存算分离模式，其它存算一体模式
   - 示例：`cloud`
2. `file_cache_path`
   - 描述：用于文件缓存的磁盘路径和其他参数，以数组形式表示，每个磁盘一项。`path` 指定磁盘路径，`total_size` 限制缓存的大小；-1 或 0 将使用整个磁盘空间。
   - 格式：[{"path":"/path/to/file_cache","total_size":21474836480},{"path":"/path/to/file_cache2","total_size":21474836480}]
   - 示例：[{"path":"/path/to/file_cache","total_size":21474836480},{"path":"/path/to/file_cache2","total_size":21474836480}]
   - 默认：[{"path":"${DORIS_HOME}/file_cache"}]

#### 5.4.1 启动和添加 BE

1. 启动 Backend：

   使用以下命令启动 Backend：

   ```bash
   bin/start_be.sh --daemon
   ```

   

2. 将 Backend 添加到集群：

   使用 MySQL 客户端连接到任意 Frontend，并执行：

   ```sql
   ALTER SYSTEM ADD BACKEND "<ip>:<heartbeat_service_port>" [PROTERTIES propertires];
   ```

   

   将 `<ip>` 替换为新 Backend 的 IP 地址，将 `<heartbeat_service_port>` 替换为其配置的心跳服务端口（默认为 9050）。

   可以通过 PROPERTIES 设置 BE 所在的 计算组。

   更详细的用法请参考 [ADD BACKEND](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/instance-management/ADD-BACKEND) 和 [REMOVE BACKEND](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/instance-management/DROP-BACKEND)。

3. 验证 Backend 状态：

   检查 Backend 日志文件（`be.log`）以确保它已成功启动并加入集群。

   您还可以使用以下 SQL 命令检查 Backend 状态：

   ```sql
   SHOW BACKENDS;
   ```

   

   这将显示集群中所有 Backend 及其当前状态。

## 6. 创建 Storage Vault

Storage Vault 是 Doris 存算分离架构中的重要组件。它们代表了存储数据的共享存储层。您可以使用 HDFS 或兼容 S3 的对象存储创建一个或多个 Storage Vault。可以将一个 Storage Vault 设置为默认 Storage Vault，系统表和未指定 Storage Vault 的表都将存储在这个默认 Storage Vault 中。默认 Storage Vault 不能被删除。以下是为您的 Doris 集群创建 Storage Vault 的方法：

### 6.1 创建 HDFS Storage Vault

要使用 SQL 创建 Storage Vault，请使用 MySQL 客户端连接到您的 Doris 集群

```sql
CREATE STORAGE VAULT IF NOT EXISTS hdfs_vault
    PROPERTIES (
    "type"="hdfs",
    "fs.defaultFS"="hdfs://127.0.0.1:8020"
    );
```



### 6.2 创建 S3 Storage Vault

要使用兼容 S3 的对象存储创建 Storage Vault，请按照以下步骤操作：

1. 使用 MySQL 客户端连接到您的 Doris 集群。
2. 执行以下 SQL 命令来创建 S3 Storage Vault：

```sql
CREATE STORAGE VAULT IF NOT EXISTS s3_vault
    PROPERTIES (
    "type"="S3",
    "s3.endpoint"="s3.us-east-1.amazonaws.com",
    "s3.access_key" = "ak",
    "s3.secret_key" = "sk",
    "s3.region" = "us-east-1",
    "s3.root.path" = "ssb_sf1_p2_s3",
    "s3.bucket" = "doris-build-1308700295",
    "provider" = "S3"
    );
```



要在其他对象存储上创建 Storage Vault，请参考 [创建 Storage Vault ](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/storage-management/CREATE-STORAGE-VAULT)。

### 6.3 设置默认 Storage Vault

使用如下 SQL 语句设置一个默认 Storage Vault。

```sql
SET <storage_vault_name> AS DEFAULT STORAGE VAULT
```



## 7. 注意事项

- 仅元数据操作功能的 Meta Service 进程应作为 FE 和 BE 的 `meta_service_endpoint` 配置目标。
- 数据回收功能进程不应作为 `meta_service_endpoint` 配置目标。

[
](https://github.com/apache/doris-website/tree/master/i18n/zh-CN/docusaurus-plugin-content-docs/version-3.0/compute-storage-decoupled/compilation-and-deployment.md)



# 管理 Storage Vault

Storage Vault 是 Doris 在存算分离模式中所使用的远程共享存储，可配置一个或多个 Storage Vault，可将不同表存储在不同 Storage Vault 上。

## 创建 Storage Vault

**语法**

```sql
CREATE STORAGE VAULT [IF NOT EXISTS] <vault_name>
PROPERTIES
("key" = "value",...)
```



<vault_name> 是用户定义的 Storage Vault 名称，是用户接口用于访问 Storage Vault 的标识。

### 创建 HDFS Storage Vault

创建基于 HDFS 的存算分离模式 Doris 集群，需要确保所有的节点 (包括 FE / BE 节点、Meta Service) 均有权限访问所指定的 HDFS，包括提前完成机器的 Kerberos 授权配置和连通性检查（可在对应的每个节点上使用 Hadoop Client 进行测试）等。

```sql
CREATE STORAGE VAULT IF NOT EXISTS hdfs_vault_demo
PROPERTIES (
    "type" = "hdfs",                                     -- required
    "fs.defaultFS" = "hdfs://127.0.0.1:8020",            -- required
    "path_prefix" = "big/data",                          -- optional,  一般按照业务名称填写
    "hadoop.username" = "user"                           -- optional
    "hadoop.security.authentication" = "kerberos"        -- optional
    "hadoop.kerberos.principal" = "hadoop/127.0.0.1@XXX" -- optional
    "hadoop.kerberos.keytab" = "/etc/emr.keytab"         -- optional
);
```



### 创建 S3 Storage Vault

```sql
CREATE STORAGE VAULT IF NOT EXISTS s3_vault_demo
PROPERTIES (
    "type" = "S3",                                 -- required
    "s3.endpoint" = "oss-cn-beijing.aliyuncs.com", -- required
    "s3.region" = "cn-beijing",                    -- required
    "s3.bucket" = "bucket",                        -- required
    "s3.root.path" = "big/data/prefix",            -- required
    "s3.access_key" = "ak",                        -- required
    "s3.secret_key" = "sk",                        -- required
    "provider" = "OSS",                            -- required
    "use_path_style" = "false"                     -- optional
);
```



更多参数说明及示例可见 [CREATE-STORAGE-VAULT](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/storage-management/CREATE-STORAGE-VAULT)。

**注意** 提供的对象存储路径必须具有head/get/list/put/multipartUpload/delete访问权限。

## 查看 Storage Vault

**语法**

```sql
SHOW STORAGE VAULTS
```



返回结果包含 4 列，分别为 Storage Vault 名称、Storage Vault ID、属性以及是否为默认 Storage Vault。

### 设置默认 Storage Vault

**语法**

```sql
SET <vault_name> AS DEFAULT STORAGE VAULT
```



## 建表时指定 Storage Vault

建表时在 `PROPERTIES` 中指定 `storage_vault_name`，则数据会存储在指定 `vault name` 所对应的 Storage Vault 上。建表成功后，该表不允许再修改 `storage_vault`，即不支持更换 Storage Vault。

**示例**

```sql
CREATE TABLE IF NOT EXISTS supplier (
  s_suppkey int(11) NOT NULL COMMENT "",
  s_name varchar(26) NOT NULL COMMENT "",
  s_address varchar(26) NOT NULL COMMENT "",
  s_city varchar(11) NOT NULL COMMENT "",
  s_nation varchar(16) NOT NULL COMMENT "",
  s_region varchar(13) NOT NULL COMMENT "",
  s_phone varchar(16) NOT NULL COMMENT ""
)
UNIQUE KEY (s_suppkey)
DISTRIBUTED BY HASH(s_suppkey) BUCKETS 1
PROPERTIES (
  "replication_num" = "1",
  "storage_vault_name" = "hdfs_demo_vault"
);
```



## 更改 Storage Vault

用于更新 Storage Vault 配置的可修改属性。

S3 Storage Vault 允许修改的属性：

- `VAULT_NAME`
- `s3.access_key`
- `s3.secret_key`
- `use_path_style`

HDFS Storage Vault 禁止修改的属性：

- `path_prefix`
- `fs.defaultFS`

更多属性说明见 [CREATE-STORAGE-VAULT](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/storage-management/CREATE-STORAGE-VAULT)。

**示例**

```sql
ALTER STORAGE VAULT old_s3_vault
PROPERTIES (
    "type" = "S3",
    "VAULT_NAME" = "new_s3_vault",
    "s3.access_key" = "new_ak"
    "s3.secret_key" = "new_sk"
);
```



```sql
ALTER STORAGE VAULT old_hdfs_vault
PROPERTIES (
    "type" = "hdfs",
    "VAULT_NAME" = "new_hdfs_vault",
    "hadoop.username" = "hdfs"
);
```



## 删除 Storage Vault

暂不支持

## Storage Vault 权限

向指定的 MySQL 用户授予某个 Storage Vault 的使用权限，使该用户可以进行建表时指定该 Storage Vault 或查看 Storage Vault 等操作。

### 授予

```sql
GRANT
    USAGE_PRIV
    ON STORAGE VAULT <vault_name>
    TO { ROLE | USER } {<role> | <user>}
```



仅 Admin 用户有权限执行 `GRANT` 语句，该语句用于向 User / Role 授予指定 Storage Vault 的权限。拥有某个 Storage Vault 的 `USAGE_PRIV` 权限的 User / Role 可进行以下操作：

- 通过 `SHOW STORAGE VAULTS` 查看该 Storage Vault 的信息；
- 建表时在 `PROPERTIES` 中指定使用该 Storage Vault。

### 撤销

```sql
grant usage_priv on storage vault my_storage_vault to user1
```



撤销指定的 MySQL 用户的 Storage Vault 权限。

**语法**

```sql
REVOKE 
    USAGE_PRIV
    ON STORAGE VAULT <vault_name>
    FROM { ROLE | USER } {<role> | <user>}
```



仅 Admin 用户有权限执行 `REVOKE` 语句，用于撤销 User / Role 拥有的对指定 Storage Vault 的权限。

**示例**

```sql
revoke usage_priv on storage vault my_storage_vault from user1
```





# 计算组操作

在存算分离架构下，可以将一个或多个计算节点 (BE) 组成一个计算组 (Compute Group)。本文档介绍如何使用计算组，其中涉及的操作包括：

- 查看所有计算组
- 计算组授权
- 在用户级别绑定计算组 (`default_compute_group`) 以达到用户级别的隔离效果

注意

3.0.2 之前的版本中叫做计算集群（Compute Cluster）。

## 计算组使用场景

在多计算组的架构下，可以通过将一个或多个无状态的 BE 节点组成计算集群，利用计算集群指定语句 (use @<compute_group_name>) 将特定负载分配到特定的计算集群中，从而实现多导入和查询负载的物理隔离。

假设当前有两个计算集群：C1 和 C2。

- **读读隔离**：在发起两个大型查询之前，分别使用 `use @c1` 和 `use @c2`，确保两个查询在不同的计算节点上运行，从而避免在访问相同数据集时因 CPU 和内存等资源竞争而相互干扰。
- **读写隔离**：Doris 的数据导入会消耗大量资源，尤其是在大数据量和高频导入的场景中。为了避免查询和导入之间的资源竞争，可以通过 `use @c1` 和 `use @c2` 指定查询在 C1 上执行，导入在 C2 上执行。同时，C1 计算集群可以访问 C2 计算集群中新导入的数据。
- **写写隔离**：与读写隔离类似，导入之间也可以进行隔离。例如，当系统中存在高频小量导入和大批量导入时，批量导入通常耗时较长且重试成本高，而高频小量导入耗时短且重试成本低。为了避免小量导入对批量导入的干扰，可以通过 `use @c1` 和 `use @c2`，将小量导入指定到 C1 上执行，批量导入指定到 C2 上执行。

## 默认计算组的选择机制

当用户未明确[设置默认计算组](https://doris.apache.org/zh-CN/docs/3.0/compute-storage-decoupled/managing-compute-cluster#设置默认计算组)时，系统将自动为用户选择一个具有存活计算节点且用户具有使用权限的计算组。在特定会话中确定默认计算组后，默认计算组将在该会话期间保持不变，除非用户显式更改了默认设置。

在不同次的会话中，若发生以下情况，系统可能会自动更改用户的默认计算组：

- 用户失去了在上次会话中所选择默认计算组的使用权限
- 有计算组被添加或移除
- 上次所选择的默认计算组不再具有存活计算节点

其中，情况一和情况二必定会导致系统自动选择的默认计算组更改，情况三可能会导致更改。

## 查看所有计算组

使用 `SHOW COMPUTE GROUPS` 命令可以查看当前仓库中的所有计算组。返回结果会根据用户权限级别显示不同内容：

- 具有 `ADMIN` 权限的用户可以查看所有计算组
- 普通用户只能查看其拥有使用权限（USAGE_PRIV）的计算组
- 如果用户没有任何计算组的使用权限，则返回结果为空

```sql
SHOW COMPUTE GROUPS;
```



## 添加计算组

操作计算组需要具备 `OPERATOR` 权限，即节点管理权限。有关详细信息，请参阅[权限管理](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/account-management/GRANT-TO)。默认情况下，只有 root 账号拥有 `OPERATOR` 权限，但可以通过 `GRANT` 命令将此权限授予其他账号。 要添加 BE 并为其指定计算组，请使用 [Add BE](https://doris.apache.org/zh-CN/docs/3.0/sql-manual/sql-statements/cluster-management/instance-management/ADD-BACKEND) 命令。例如：

```sql
ALTER SYSTEM ADD BACKEND 'host:9050' PROPERTIES ("tag.compute_group_name" = "new_group");
```



上面命令会将`host:9050`这台节点添加到`new_group`这个计算组中，您也可以不指定计算组，默认会添加到`default_compute_group`组里，示例：

```sql
ALTER SYSTEM ADD BACKEND 'host:9050';
```



## 授予计算组访问权限

前置条件：当前操作用户具备 `ADMIN` 权限，或者当前用户属于 admin role。

```sql
GRANT USAGE_PRIV ON COMPUTE GROUP {compute_group_name} TO {user};
```



## 撤销计算组访问权限

前置条件：当前操作用户具备 `ADMIN` 权限，或者当前用户属于 admin role。

```sql
REVOKE USAGE_PRIV ON COMPUTE GROUP {compute_group_name} FROM {user};
```



## 设置默认计算组

为当前用户设置默认计算组（此操作需要当前用户已经拥有计算组的使用权限）：

```sql
SET PROPERTY 'default_compute_group' = '{clusterName}';
```



为其他用户设置默认计算组（此操作需要 Admin 权限）：

```sql
SET PROPERTY FOR {user} 'default_compute_group' = '{clusterName}';
```



查看当前用户默认计算组，返回结果中`default_compute_group` 的值即为默认计算组：

```sql
SHOW PROPERTY;
```



查看其他用户默认计算组，此操作需要当前用户具备 admin 权限，返回结果中`default_compute_group` 的值即为默认计算组：

```sql
SHOW PROPERTY FOR {user};
```



查看当前仓库下所有可用的计算组：

```sql
SHOW COMPUTE GROUPS;
```



备注

- 若当前用户拥有 Admin 角色，例如：`CREATE USER jack IDENTIFIED BY '123456' DEFAULT ROLE "admin"`，则：
  - 可以为自身以及其他用户设置默认计算组；
  - 可以查看自身以及其他用户的 `PROPERTY`。
- 若当前用户无 Admin 角色，例如：`CREATE USER jack1 IDENTIFIED BY '123456'`，则：
  - 可以为自身设置默认计算组；
  - 可以查看自身的 `PROPERTY`；
  - 无法查看所有计算组，因该操作需要 `GRANT ADMIN` 权限。
- 若当前用户未配置默认计算组，现有系统在执行数据读写操作时将会触发错误。为解决这一问题，用户可通过执行 `use @cluster` 命令来指定当前 Context 所使用的计算组，或者使用 `SET PROPERTY` 语句来设置默认计算组。
- 若当前用户已配置默认计算组，但随后该集群被删除，则在执行数据读写操作时同样会触发错误。用户可通过执行 `use @cluster` 命令来重新指定当前 Context 所使用的计算组，或者利用 `SET PROPERTY` 语句来更新默认集群设置。

## 切换计算组

用户可在存算分离架构中指定使用的数据库和计算组。

**语法**

```sql
USE { [catalog_name.]database_name[@compute_group_name] | @compute_group_name }
```



若数据库或计算组名称包含是保留关键字，需用反引号将相应的名称 ``` 包围。

## 计算组扩缩容

通过 `ALTER SYSTEM ADD BACKEND` 以及 `ALTER SYSTEM DECOMMISION BACKEND` 添加或者删除 BE 实现计算组的扩缩容。

















