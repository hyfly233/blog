# 分布式事务

## 分布式事务

-   分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上，分布式事务需要保证这些小操作要么全部成功，要么全部失败
-   对于分布式系统而言，需要保证分布式系统中的数据一致性，避免业务出现问题。分布式系统中对数要么一起成功，要么一起失败，必须是一个整体性的事务
-   当本地事务要扩展到分布式时，它的复杂性进一步增加

-   -   存储端的多样性：本地事务的情况下，所有数据都会落到同一个 DB 中，但是，在分布式的情况下，就会出现数据可能要落到多个 DB，或者还会落到 Redis，落到 MQ 等中
    -   事务链路的延展性：本地事务的情况下，通常所有的事务相关的业务操作会被封装到一个 Service 方法中。而在分布式的情况下，请求链路被延展伸长，一个操作被拆分成多个服务，它们呈线性或网状，依靠网络通信构成一个整体，事务变得十分复杂

## 分布式事务使用场景

-   跨库事务
-   分库分表
-   微服务化

## 事务组成

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/29236088/1676448575049-8c663679-1e52-4b1f-8226-73ecc6ae22fd.jpeg)

-   事务：事务是由一组操作构成的可靠的独立的工作单元，事务具备 ACID 的特性，即原子性、一致性、隔离性和持久性
-   本地事务：当事务由资源管理器本地管理时被称作本地事务。本地事务的优点就是支持严格的 ACID 特性，高效，可靠，状态可以只在资源管理器中维护，而且应用编程模型简单。但是本地事务不具备分布式事务的处理能力，隔离的最小单位受限于资源管理器
-   全局事务：当事务由全局事务管理器进行全局管理时成为全局事务，事务管理器负责管理全局的事务状态和参与的资源，协同资源的一致提交回滚
-   TX 协议：应用或者应用服务器与事务管理器的接口
-   XA 协议：全局事务管理器与资源管理器的接口。XA 是由 X/Open 组织提出的分布式事务规范。该规范主要定义了全局事务管理器和局部资源管理器之间的接口。主流的数据库产品都实现了 XA 接口。XA 接口是一个双向的系统接口，在事务管理器以及多个资源管理器之间作为通信桥梁。之所以需要 XA 是因为在分布式系统中从理论上讲两台机器是无法达到一致性状态的，因此引入一个单点进行协调。由全局事务管理器管理和协调的事务可以跨越多个资源和进程。全局事务管理器一般使用 XA 二阶段协议与数据库进行交互
-   AP：应用程序，可以理解为使用 DTP（Data Tools Platform）的程序
-   RM：资源管理器，可以是一个 DBMS 或者消息服务器管理系统，应用程序通过资源管理器对资源进行控制，资源必须实现 XA 定义的接口。资源管理器负责控制和管理实际的资源
-   TM：事务管理器，负责协调和管理事务，提供给 AP 编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源
-   两阶段提交协议：XA 用于在全局事务中协调多个资源的机制。TM 和 RM 之间采取两阶段提交的方案来解决一致性问题。两节点提交需要一个协调者（TM）来掌控所有参与者（RM）节点的操作结果并且指引这些节点是否需要最终提交。两阶段提交的局限在于协议成本，准备阶段的持久成本，全局事务状态的持久成本，潜在故障点多带来的脆弱性，准备后，提交前的故障引发一系列隔离与恢复难题。
-   BASE 理论：BA 指的是基本业务可用性，支持分区失败，S 表示柔性状态，也就是允许短时间内不同步，E 表示最终一致性，数据最终是一致的，但是实时是不一致的。原子性和持久性必须从根本上保障，为了可用性、性能和服务降级的需要，只有降低一致性和隔离性的要求。
-   CAP 定理：对于共享数据系统，最多只能同时拥有 CAP 其中的两个，任意两个都有其适应的场景，真是的业务系统中通常是 ACID 与 CAP 的混合体。分布式系统中最重要的是满足业务需求，而不是追求高度抽象，绝对的系统特性。C 表示一致性，也就是所有用户看到的数据是一样的。A 表示可用性，是指总能找到一个可用的数据副本。P 表示分区容错性，能够容忍网络中断等故障。

## 分布式事务与分布式锁的区别

-   分布式锁解决的是分布式资源抢占的问题
-   分布式事务和本地事务是解决流程化提交问题

## CAP

## BASE

BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的缩写。BASE 基于 CAP 定理演化而来，核心思想是即时无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

-   Basically Available（基本可用）：指分布式系统中出现不可预知故障的时候，允许损失部分可用性，但不等于系统不可用

-   -   响应时间上的损失：当出现故障时，响应时间增加
    -   功能上的损失：当流量高峰时，屏蔽一些功能的使用以爆炸系统的稳定性（服务降级）

-   Soft state（软状态）：数据存在中间状态，并认为改中间状态不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时
-   Eventually consistent（最终一致性）：系统中的所有数据副本，经过一段时间的同步后，最终能够达到一个一致的状态

-   -   因果一致性（Causal Consistency）：即进程 A 在更新完数据后通知进程 B，那么之后进程 B 对该项数据的范围都是进程 A 更新后的最新值
    -   读己之所写（Read your writes）：进程 A 更新一项数据后，它自己总是能访问到自己更新过的最新值
    -   会话一致型（Session consistency）：将数据一致性框定在会话当中，在一个会话当中实现读己之所写的一致性。即执行更新后，客户端在同一个会话中始终能读到该项数据的最新值
    -   单调读一致型（Monotonic read consistency）：如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值
    -   单调写一致型（Monotonic write consistency）：一个系统需要保证来自同一个进程的写操作被顺序执行

## 解决方案

-   强一致性

-   -   二阶段提交
    -   Raft

-   最终一致性

-   -   异步确保型
    -   事务型消息
    -   TCC 型

## 二阶段提交

排它锁保证强一致性

二阶段提交非常影响性能

## Raft 协议

对 N 个节点的集群中，同步成功一半以上（N/2 + 1）个节点就算同步成功，外加二阶段提交

## TCC

依照二阶段提交设计的，Try，Confirm，Cancel

需要中间状态字段，log 表

需要定时补偿机制

## 异步确保型

消息中间件需要持久化消息，并且开启重试

回滚操作发送 mq 可能会失败

## 事务型消息

本地事务开始前，先向 RocketMQ 发送 prepare 消息，再执行本地事务后 commit，send commit 消息

RocketMQ 会根据 prepare 消息进行会查

## 什么是 CAP 理论

CAP 理论是分布式领域中非常重要的一个指导理论，C（Consistency）表示强一致性，A（Availability）表示可用性，P（PartitionTolerance）表示分区容错性，CAP 理论指出在目前的硬件条件下，一个分布式系统是必须要保证分区容错性的，而在这个前提下，分布式系统要么保证 CP，要么保证 AP，无法同时保证 CAP。

-   分区容错性表示，一个系统虽然是分布式的，但是对外看上去应该是一个整体，不能由于分布式系统内部的某个结点挂点，或网络出现了故障，而导致系统对外出现异常。所以，对于分布式系统而言是一定要保证分区容错性的
-   强一致性表示，一个分布式系统中各个结点之间能及时的同步数据，在数据同步过程中，是不能对外提供服务的，不然就会造成数据不一致，所以
    强一致性和可用性是不能同时满足的
-   可用性表示，一个分布式系统对外要保证可用

## 什么是 BASE 理论

由于不能同时满足 CAP，所以出现了 BASE 理论

1. BA：`BasicallyAvailable`，表示基本可用，表示可以允许一定程度的不可用，比如由于系统故障，请求时间变长，或者由于系统故障导致部分非核心功能不可用，都是允许的
2. S：`Softstate`：表示分布式系统可以处于一种中间状态，比如数据正在同步
3. E：`Eventuallyconsistent`，表示最终一致性，不要求分布式系统数据实时达到一致，允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的

## 什么是 RPC

RPC，表示远程过程调用，对于 Java 这种面试对象语言，也可以理解为远程方法调用

RPC 调用和 HTTP 调用是有区别的

RPC 表示的是一种调用远程方法的方式，可以使用 HTTP 协议、或直接基于 TCP 协议来实现 RPC，在 Java 中，可以通过直接使用某个服务接口的代理对象来执行方法，而底层则通过构造

HTTP 请求来调用远端的方法，所以，有一种说法是 RPC 协议是 HTTP 协议之上的一种协议

## 分布式 ID 是什么？ 有哪些解决方案？

在开发中，我们通常会需要一个唯 ID 来标识数据，如果是单体架构，我们可以通过数据库的主键，或直接在内存中维护一个自增数字来作为 ID 都是可以的，但对于一个分布式系统，就会有可能会出现 I 冲突，此时有以下解决方案

1. uuid，这种方案复杂度最低，但是会影响存储空间和性能
2. 利用单机数据库的自增主键，作为分布式 ID 的生成器，复杂度适中，ID 长度较之 uuid 更短，但是受到单机数据库性能的限制，并发量大的时候此方案也不是最优方案
3. 利用 redis、zookeeper 的特性来生成 id，比如 redis 的自增命令、zookeeper 的顺序节点，这种方案和单机数据库（mysql）相比，性能有所提高，可以适当选用
4. 雪花算法，一切问题如果能直接用算法解决，那就是最合适的，利用雪花算法也可以生成分布式 ID，底层原理就是通过某台机器在某一毫秒内对某一个数字自增，这种方案也能保证分布式架构中的系统 id 唯一，但是只能保证超势递增。业界存在`tinyid`、`lea`等开源中间件实现了雪花算法

## 分布式锁的使用场景是什么？ 有哪些实现方案？

在单体架构中，多个线程都是属于同一个进程的，所以在线程并发执行时，遇到资源竞争时，可以利用`Reentrantlock`、`synchronized`等技术来作为锁，来控制共享资源的使用。

分布式架构中，多个线程是可能处于不同进程中的，而这些线程并发执行遇到资源竞争时，利用`ReentrantLock`、`synchronized`等技术是没办法来控制多个进程中的线程的，所以需要分布式锁，意思就是，需要一个分布式锁生成器，分布式系统中的应用程序都可以来使用这个生成器所提供的锁，从而达到多个进程中的线程使用同一把锁

当前主流的分布式锁的实现方案有两种

1. zookeeper：利用的是 zookeeper 的临时节点、顺序节点、watch 机制来实现的，zookeeper 分布式锁的特点是高一致性，因为 zookeeper 保证的是 CP，所以由它实现的分布式锁更可靠，不会出现混乱
2. redis：利用 redis 的 setnx、lua 脚本、消费订阅等机制来实现的，redis 分布式锁的特点是高可用，因为 redis 保证的是 AP，所以由它实现的分布式可能不可靠，不稳定（一旦 redis 中的数据出现了不一致），可能会出现多个客户端同时加到锁的情况

## 什么是分布式事务？有哪些实现方案？

在分布式系统中，一次业务处理可能需要多个应用来实现，比如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存，而对于次下单，订单创建与减库存应该是要同时成功或同时失败的，但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败，那么解决这类问题，就需要用到分布式事务。

常用解决方案有：

1. 本地消息表：创建订单时，将减库存消息加入在本地事务中，一起提交到数据库存入本地消息表，然后调用库存系统，如果调用成功则修改本地消息状态为成功，如果调用库存系统失败，则由后台定时任务从本地消息表中取出未成功的消息，重试调用库存系统
2. 消息队列：目前 RocketMQ 中支持事务消息，它的工作原理是：
   a.生产者订单系统先发送一条 half 消息到 Broker，half 消息对消费者而言是不可见的
   b.再创建订单，根据创建订单成功与否，向 Broker 发送 commit 或 rollback
   c.并且生产者订单系统还可以提供 Broker 回调接口，当 Broker 发现一段时间 half 消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
   d.一旦 half 消息 commit 了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
   e.如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理
3. Seata：阿里开源的分布式事务框架，支持 AT、TCC 等多种模式，底层都是基于两阶段提交理论来实现的

## 数据一致性模型有哪些

-   强一致性：当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新过的值，这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要性可用性。
-   弱一致性：系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到用户读到某一操作对系统数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
-   最终一致性：最终一致性是弱一致性的特例，强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态
    因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。到达最终一致性的时间，就是不一致窗口时间，在没有故障发生的前提下，不一致窗口的时间主要受通信延，系统负载和复制副本的个数影响，最终一致性模型根据其提供的不同保证可以划分为更多的模型，包括因果一致性和会话一致性等
-   因果一致性：要求有因果关系的操作顺序得到保证
    非因果关系的操作顺序则无所谓进程 A 在更新完某个数据项后通知了进程 B，那么进程 B 之后对该数据项的访问都应该能够获取到进程 A 更新后的最新值，并且如果进程 B 要对该数据项进行更新操作的话，务必基于进程 A 更新后的最新值
    在微博或者微信进行评论的时候，比如你在朋友圈发了一张照片，朋友给你评论了，而你对朋友的评论进行了回复，这条朋友圈的显示中，你的回复必须在朋友之后，这是一个因果关系，而其他没有因果关系的数据，可以允许不一致
-   会话一致性：将对系统数据的访问过程框定在了一个会话当中，约定了系统能保证在同一个有效的会话中实现读己之所写的一致性，就是在你的一次访问中，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。实际开发中有分布式的 Session 一致性问题，可以认为是会话一致性的一个应用

## 选举算法 Quorum 机制、 WARO

-   Waro：一种简单的副本控制协议，写操作时、只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败
    优先保证读、任何节点读到的数据都是最新数据，性了更新服务的可用性、只要有一个副本岩机了，写服务就不会成功。但只要有一个节点存活、仍能提供读服务
-   Quorum 机制：10 个副本，一次成功更新了三个，那么至少需要读取八个副本的数据，可以保证读到了最新的数据
    无法保证强一致性，也就是无法实现任何时刻任何用户或节点都可以读到最近一次成功提交的副本数据。需要配合一个获取最新成功提交的版本号的 metadata 服务，这样可以确定最新已经成功提交的版本号，然后从已经读到的数据中就可以确认最新写入的数据

## Seata

### Seata 是什么

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式的分布式解决方案，Seata AT 和 Seata TCC 是在生产中最常用

### Seata 的三大模块

-   TC：事务协调者。负责事务 ID 的生成，事务注册、提交、回滚等
-   TM：事务发起者。定义事务的边界，负责告知 TC，分布式事务的开始，提交，回滚
-   RM：资源管理者。管理每个分支事务的资源，每一个 RM 都会作为一个分支事务注册在 TC

在 Seata 的 AT 模式中，TM 和 RM 都作为 SDK 的一部分和业务服务在一起，可以认为是 Client。TC 是一个独立的服务，通过服务注册发现将自己暴露给 Client 们

### Seata 执行流程

1. TM 开启分布式事务（TM 向 TC 注册全局事务记录）
2. 按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）
3. TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）
4. TC 汇总事务信息，决定分布式事务是提交还是回滚
5. TC 通知所有 RM 提交/回滚资源，事务二阶段结束

### Seata AT 模式

AT 模式是指**Automatic (Branch) Transaction Mode 自动化分支事务**，AT 模式，是 2pc 两阶段提交协议的演变，不同的地方，Seata AT 模式不会一直锁表。

**使用前提：**

-   基于支持本地 ACID 事务的关系型数据库
-   Java 应用通过 JDBC 访问数据库

### Seata TCC 模式

TCC 与 Seata AT 事务一样都是**两阶段事务**，它与 AT 事务的主要区别为：

-   **TCC 对业务代码侵入严重**
    每个阶段的数据操作都要自己进行编码来实现，事务框架无法自动处理
-   **TCC 性能更高**
    不必对数据加全局锁，允许多个事务同时操作数据

### Seata Saga 模式

Saga 模式是 Seata 提供的长事务解决方案，在 Saga 模式中，业务流程中每个参与者都提交本地事务，当出现某一个参与者失败则补偿前面已经成功的参与者，一阶段正向服务和二阶段补偿服务都由业务开发实现。

**适用场景：**

-   业务流程长、业务流程多
-   参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口

**优势：**

-   一阶段提交本地事务，无锁，高性能
-   事件驱动架构，参与者可异步执行，高吞吐
-   补偿服务易于实现

**缺点：**

-   不保证隔离性

### Seata XA 模式

在 Seata 定义的分布式事务框架内，利用事务资源（数据库、消息服务等）对 XA 协议的支持，以 XA 协议的机制来管理分支事务的一种 事务模式

**使用前提：**

-   支持 XA 事务的数据库
-   Java 应用，通过 JDBC 访问数据库

# 说一下两阶段提交和三阶段提交的过程？分别有什么问题？

两阶段提交协议 2PC

1. 第一阶段（投票阶段）：

（1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应；

（2）参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志。

（3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。

2. 第二阶段（提交执行阶段）：

当协调者节点从所有参与者节点获得的相应消息都为”同意”时：

（1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求；

（2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源；

（3）参与者节点向协调者节点发送”完成”消息；

（4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。

两阶段提交存在的问题：

1. 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态；
2. 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败；
3. 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错；
4. 二阶段无法解决的问题：协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

三阶段提交协议 3PC

与两阶段提交不同的是，三阶段提交有两个改动点：

1. 引入超时机制。同时在协调者和参与者中都引入超时机制；
2. 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段。

1. CanCommit 阶段

3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应。

（1）事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。

（2）响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态。否则反馈 No。

2. PreCommit 阶段

协调者根据参与者的反应情况来决定是否可以继续事务的 PreCommit 操作。根据响应情况，有以下两种可能：

假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行。

（1）发送预提交请求：协调者向参与者发送 PreCommit 请求，并进入 Prepared 阶段。

（2）事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 undo 和 redo 信息记录到事务日志中。

（3）响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。

假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。

（1）发送中断请求：协调者向所有参与者发送 abort 请求。

（2）中断事务：参与者收到来自协调者的 abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。

3. doCommit 阶段

该阶段进行真正的事务提交，也可以分为以下两种情况。

3.1 执行提交

（1）发送提交请求：协调接收到参与者发送的 ACK 响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送 doCommit 请求。

（2）事务提交：参与者接收到 doCommit 请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。

（3）响应反馈：事务提交完之后，向协调者发送 ACK 响应。

（4）完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务。

3.2 中断事务

协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务。

（1）发送中断请求：协调者向所有参与者发送 abort 请求。

（2）事务回滚：参与者接收到 abort 请求之后，利用其在阶段二记录的 undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。

（3）反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息。

（4）中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断。

三阶段提交的问题：

网络分区可能会带来问题。需要四阶段解决：四阶段直接调用远程服务的数据状态，确定当前数据一致性的情况。

# 分布式事务详解

## 第一章 分布式事务概述

### 1.1 什么是分布式事务

分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。分布式事务需要保证这些分布的操作要么全部成功，要么全部失败，确保数据的一致性。

**核心特征：**

-   **跨节点性**：事务操作跨越多个网络节点
-   **原子性**：所有参与的操作必须全部成功或全部失败
-   **一致性**：确保分布式系统中的数据一致性
-   **复杂性**：相比本地事务，实现复杂度大幅增加

### 1.2 分布式事务的挑战

当本地事务扩展到分布式环境时，面临以下主要挑战：

#### 1.2.1 存储端的多样性

-   **本地事务**：所有数据操作在同一个数据库中完成
-   **分布式事务**：数据可能分布在多个数据库、Redis 缓存、消息队列等不同存储系统中

#### 1.2.2 事务链路的延展性

-   **本地事务**：所有操作封装在一个 Service 方法中
-   **分布式事务**：请求链路延展到多个服务，形成线性或网状调用关系，依靠网络通信构成整体

### 1.3 典型使用场景

#### 1.3.1 跨库事务

不同业务模块的数据存储在不同的数据库中，需要保证跨库操作的一致性。

#### 1.3.2 分库分表

同一业务的数据水平拆分到多个数据库表中，需要保证分片操作的原子性。

#### 1.3.3 微服务化

在微服务架构中，一个业务流程可能涉及多个微服务，需要保证服务间调用的事务一致性。

**典型案例：电商下单流程**

```java
// 分布式事务示例：下单流程
@Service
public class OrderService {

    @GlobalTransactional
    public void createOrder(OrderDTO orderDTO) {
        // 1. 创建订单（订单服务）
        orderRepository.save(order);

        // 2. 扣减库存（库存服务）
        inventoryService.reduceStock(orderDTO.getProductId(), orderDTO.getQuantity());

        // 3. 扣减余额（账户服务）
        accountService.reduceBalance(orderDTO.getUserId(), orderDTO.getAmount());

        // 4. 发送消息（消息服务）
        messageService.sendOrderNotification(orderDTO);
    }
}
```

## 第二章 分布式事务理论基础

### 2.1 事务基本概念

#### 2.1.1 事务特性

事务是由一组操作构成的可靠的独立的工作单元，具备 ACID 特性：

-   **原子性（Atomicity）**：事务中的所有操作要么全部成功，要么全部失败
-   **一致性（Consistency）**：事务执行前后，数据的完整性保持一致
-   **隔离性（Isolation）**：并发执行的事务之间相互隔离
-   **持久性（Durability）**：事务提交后，数据永久保存

#### 2.1.2 本地事务 vs 全局事务

| 特性      | 本地事务           | 全局事务             |
| --------- | ------------------ | -------------------- |
| 管理方式  | 资源管理器本地管理 | 全局事务管理器管理   |
| ACID 支持 | 严格支持           | 部分支持或最终一致性 |
| 性能      | 高效               | 相对较低             |
| 复杂度    | 简单               | 复杂                 |
| 适用场景  | 单体应用           | 分布式系统           |

### 2.2 分布式事务协议

#### 2.2.1 XA 协议

XA 是由 X/Open 组织提出的分布式事务规范，定义了全局事务管理器和局部资源管理器之间的接口。

**XA 协议角色：**

-   **AP（Application Program）**：应用程序，使用 DTP 的程序
-   **RM（Resource Manager）**：资源管理器，管理实际资源（如数据库）
-   **TM（Transaction Manager）**：事务管理器，协调和管理全局事务

```java
// XA协议示例
public class XATransactionExample {
    public void performXATransaction() throws Exception {
        // 1. 获取XA资源
        XADataSource xaDataSource1 = new MysqlXADataSource();
        XADataSource xaDataSource2 = new MysqlXADataSource();

        XAConnection xaConn1 = xaDataSource1.getXAConnection();
        XAConnection xaConn2 = xaDataSource2.getXAConnection();

        XAResource xaRes1 = xaConn1.getXAResource();
        XAResource xaRes2 = xaConn2.getXAResource();

        // 2. 创建事务分支
        Xid xid1 = new MyXid(100, new byte[]{0x01}, new byte[]{0x02});
        Xid xid2 = new MyXid(100, new byte[]{0x11}, new byte[]{0x12});

        try {
            // 3. 开始事务分支
            xaRes1.start(xid1, XAResource.TMNOFLAGS);
            xaRes2.start(xid2, XAResource.TMNOFLAGS);

            // 4. 执行业务操作
            Connection conn1 = xaConn1.getConnection();
            Connection conn2 = xaConn2.getConnection();

            PreparedStatement ps1 = conn1.prepareStatement("UPDATE account SET balance = balance - ? WHERE id = ?");
            ps1.setDouble(1, 100);
            ps1.setInt(2, 1);
            ps1.executeUpdate();

            PreparedStatement ps2 = conn2.prepareStatement("UPDATE account SET balance = balance + ? WHERE id = ?");
            ps2.setDouble(1, 100);
            ps2.setInt(2, 2);
            ps2.executeUpdate();

            // 5. 结束事务分支
            xaRes1.end(xid1, XAResource.TMSUCCESS);
            xaRes2.end(xid2, XAResource.TMSUCCESS);

            // 6. 两阶段提交
            // 第一阶段：prepare
            int ret1 = xaRes1.prepare(xid1);
            int ret2 = xaRes2.prepare(xid2);

            // 第二阶段：commit
            if (ret1 == XAResource.XA_OK && ret2 == XAResource.XA_OK) {
                xaRes1.commit(xid1, false);
                xaRes2.commit(xid2, false);
            }
        } catch (Exception e) {
            // 回滚
            xaRes1.rollback(xid1);
            xaRes2.rollback(xid2);
            throw e;
        }
    }
}
```

#### 2.2.2 TX 协议

TX 协议定义了应用程序或应用服务器与事务管理器之间的接口，提供了事务的开始、提交、回滚等操作。

### 2.3 CAP 理论

CAP 理论是分布式系统设计的重要指导原则，指出分布式系统无法同时满足以下三个特性：

#### 2.3.1 一致性（Consistency）

所有节点在同一时间看到的数据是一致的。

#### 2.3.2 可用性（Availability）

系统在任何时候都能提供服务，即使部分节点出现故障。

#### 2.3.3 分区容错性（Partition Tolerance）

系统能够容忍网络分区故障，继续提供服务。

**CAP 定理的含义：**

-   分布式系统必须保证分区容错性（P）
-   在网络分区的情况下，只能在一致性（C）和可用性（A）之间选择一个
-   CP 系统：保证一致性，牺牲可用性（如 ZooKeeper）
-   AP 系统：保证可用性，牺牲一致性（如 Redis）

### 2.4 BASE 理论

BASE 理论是对 CAP 理论的延伸，为分布式系统提供了更实用的设计指导：

#### 2.4.1 基本可用（Basically Available）

系统出现故障时，允许损失部分可用性，但不等于系统完全不可用：

-   **响应时间损失**：响应时间适当增加
-   **功能损失**：服务降级，关闭部分非核心功能

#### 2.4.2 软状态（Soft State）

允许系统存在中间状态，该状态不影响系统整体可用性。数据在不同节点间的副本同步允许存在延时。

#### 2.4.3 最终一致性（Eventually Consistent）

系统中所有数据副本经过一段时间的同步后，最终能够达到一致状态。

**最终一致性类型：**

1. **因果一致性（Causal Consistency）**

    ```java
    // 示例：微博评论系统
    // 用户A发布微博 -> 用户B评论 -> 用户A回复
    // 保证：用户A的回复必须在用户B的评论之后显示
    ```

2. **读己之所写（Read Your Writes）**

    ```java
    // 示例：用户更新个人信息后，立即能看到更新后的信息
    ```

3. **会话一致性（Session Consistency）**

    ```java
    // 示例：用户在同一session中的操作保持一致性
    ```

4. **单调读一致性（Monotonic Read Consistency）**

    ```java
    // 示例：读取到新版本数据后，后续读取不会返回旧版本
    ```

5. **单调写一致性（Monotonic Write Consistency）**
    ```java
    // 示例：来自同一进程的写操作按顺序执行
    ```

## 第三章 分布式事务解决方案

### 3.1 解决方案分类

分布式事务解决方案主要分为两大类：

#### 3.1.1 强一致性解决方案

-   **两阶段提交（2PC）**
-   **三阶段提交（3PC）**
-   **Raft 协议**

#### 3.1.2 最终一致性解决方案

-   **本地消息表**
-   **事务型消息（如 RocketMQ 事务消息）**
-   **TCC（Try-Confirm-Cancel）**
-   **Saga 模式**

### 3.2 两阶段提交（2PC）

两阶段提交是最经典的分布式事务解决方案，通过协调者统一协调所有参与者的行为。

#### 3.2.1 执行流程

**第一阶段（准备阶段）：**

1. 协调者向所有参与者发送 prepare 请求
2. 参与者执行事务操作，写入 undo 和 redo 日志
3. 参与者向协调者返回准备结果（vote）

**第二阶段（提交阶段）：**

1. 如果所有参与者都投票同意，协调者发送 commit 请求
2. 如果有参与者投票拒绝，协调者发送 rollback 请求
3. 参与者执行相应操作并释放资源

```java
// 2PC协调者实现示例
public class TwoPhaseCommitCoordinator {
    private List<Participant> participants;

    public boolean executeGlobalTransaction() {
        String transactionId = generateTransactionId();

        // 第一阶段：准备阶段
        boolean allPrepared = prepare(transactionId);

        if (allPrepared) {
            // 第二阶段：提交阶段
            return commit(transactionId);
        } else {
            // 第二阶段：回滚阶段
            rollback(transactionId);
            return false;
        }
    }

    private boolean prepare(String transactionId) {
        for (Participant participant : participants) {
            try {
                boolean prepared = participant.prepare(transactionId);
                if (!prepared) {
                    return false;
                }
            } catch (Exception e) {
                log.error("Participant prepare failed", e);
                return false;
            }
        }
        return true;
    }

    private boolean commit(String transactionId) {
        boolean allCommitted = true;
        for (Participant participant : participants) {
            try {
                participant.commit(transactionId);
            } catch (Exception e) {
                log.error("Participant commit failed", e);
                allCommitted = false;
            }
        }
        return allCommitted;
    }

    private void rollback(String transactionId) {
        for (Participant participant : participants) {
            try {
                participant.rollback(transactionId);
            } catch (Exception e) {
                log.error("Participant rollback failed", e);
            }
        }
    }
}
```

#### 3.2.2 优缺点分析

**优点：**

-   实现相对简单
-   强一致性保证
-   广泛的数据库支持

**缺点：**

-   同步阻塞：所有参与者在等待协调者决策时被阻塞
-   单点故障：协调者故障导致整个事务无法继续
-   脑裂问题：网络分区可能导致数据不一致
-   性能较差：需要多次网络通信

### 3.3 三阶段提交（3PC）

三阶段提交是对 2PC 的改进，引入了超时机制和预提交阶段。

#### 3.3.1 执行流程

**第一阶段（CanCommit）：**

1. 协调者询问参与者是否可以提交事务
2. 参与者返回 Yes 或 No 响应

**第二阶段（PreCommit）：**

1. 如果所有参与者返回 Yes，发送 PreCommit 请求
2. 参与者执行事务操作，记录日志，返回 ACK
3. 如果有参与者返回 No，发送 abort 请求

**第三阶段（DoCommit）：**

1. 协调者收到所有 ACK 后，发送 DoCommit 请求
2. 参与者正式提交事务，释放资源

```java
// 3PC参与者实现示例
public class ThreePhaseCommitParticipant {
    private TransactionState state = TransactionState.INIT;
    private String currentTransactionId;

    // 第一阶段：CanCommit
    public boolean canCommit(String transactionId) {
        this.currentTransactionId = transactionId;
        // 检查资源是否可用
        boolean canCommit = checkResourceAvailability();
        if (canCommit) {
            state = TransactionState.CAN_COMMIT;
        }
        return canCommit;
    }

    // 第二阶段：PreCommit
    public boolean preCommit(String transactionId) {
        if (!transactionId.equals(currentTransactionId) ||
            state != TransactionState.CAN_COMMIT) {
            return false;
        }

        try {
            // 执行事务操作，记录日志
            executeTransactionOperations();
            writeTransactionLog();
            state = TransactionState.PRE_COMMITTED;
            return true;
        } catch (Exception e) {
            log.error("PreCommit failed", e);
            return false;
        }
    }

    // 第三阶段：DoCommit
    public boolean doCommit(String transactionId) {
        if (!transactionId.equals(currentTransactionId) ||
            state != TransactionState.PRE_COMMITTED) {
            return false;
        }

        try {
            // 正式提交事务
            commitTransaction();
            releaseResources();
            state = TransactionState.COMMITTED;
            return true;
        } catch (Exception e) {
            log.error("DoCommit failed", e);
            return false;
        }
    }

    // 超时处理
    @Scheduled(fixedDelay = 30000)
    public void handleTimeout() {
        if (state == TransactionState.PRE_COMMITTED) {
            // 在PreCommit状态下超时，默认提交
            doCommit(currentTransactionId);
        }
    }
}
```

### 3.4 Raft 协议

Raft 是一种用于管理复制日志的共识算法，通过选举机制和日志复制确保强一致性。

#### 3.4.1 核心概念

-   **Leader**：处理所有客户端请求，管理日志复制
-   **Follower**：被动接收 Leader 的日志条目
-   **Candidate**：Leader 选举过程中的临时状态

#### 3.4.2 工作原理

1. **Leader 选举**：通过心跳机制和投票选出 Leader
2. **日志复制**：Leader 将操作记录到日志，并复制给 Followers
3. **安全保证**：只有获得大多数节点确认的日志条目才能被提交

```java
// Raft协议简化实现
public class RaftNode {
    private NodeState state = NodeState.FOLLOWER;
    private int currentTerm = 0;
    private String votedFor = null;
    private List<LogEntry> log = new ArrayList<>();
    private int commitIndex = 0;

    // Leader选举
    public void startElection() {
        state = NodeState.CANDIDATE;
        currentTerm++;
        votedFor = nodeId;

        // 向其他节点请求投票
        int votes = 1; // 自己的票
        for (RaftNode peer : peers) {
            if (peer.requestVote(currentTerm, nodeId, getLastLogIndex(), getLastLogTerm())) {
                votes++;
            }
        }

        // 获得大多数选票，成为Leader
        if (votes > peers.size() / 2) {
            state = NodeState.LEADER;
            sendHeartbeats();
        }
    }

    // 日志复制
    public boolean appendEntries(int term, String leaderId, int prevLogIndex,
                                int prevLogTerm, List<LogEntry> entries, int leaderCommit) {
        if (term < currentTerm) {
            return false;
        }

        if (term > currentTerm) {
            currentTerm = term;
            votedFor = null;
            state = NodeState.FOLLOWER;
        }

        // 检查日志一致性
        if (prevLogIndex > 0 &&
            (log.size() <= prevLogIndex || log.get(prevLogIndex - 1).getTerm() != prevLogTerm)) {
            return false;
        }

        // 追加新的日志条目
        if (!entries.isEmpty()) {
            log.addAll(entries);
        }

        // 更新提交索引
        if (leaderCommit > commitIndex) {
            commitIndex = Math.min(leaderCommit, log.size());
            applyLogEntries();
        }

        return true;
    }
}
```

### 3.5 TCC 模式

TCC（Try-Confirm-Cancel）是一种补偿型分布式事务解决方案，将事务分为三个阶段。

#### 3.5.1 三个阶段

**Try 阶段：**

-   尝试执行业务操作
-   预留必要的业务资源
-   进行参数校验和权限检查

**Confirm 阶段：**

-   确认执行业务操作
-   使用 Try 阶段预留的资源
-   Confirm 操作必须保证幂等性

**Cancel 阶段：**

-   释放 Try 阶段预留的资源
-   回滚业务操作
-   Cancel 操作必须保证幂等性

#### 3.5.2 TCC 实现示例

```java
// TCC接口定义
public interface AccountTccService {

    /**
     * Try阶段：预留账户金额
     */
    @TccTransaction
    boolean tryDebit(@TccParticipant String accountId, BigDecimal amount);

    /**
     * Confirm阶段：确认扣款
     */
    void confirmDebit(String accountId, BigDecimal amount);

    /**
     * Cancel阶段：取消扣款，释放预留金额
     */
    void cancelDebit(String accountId, BigDecimal amount);
}

// TCC实现类
@Service
public class AccountTccServiceImpl implements AccountTccService {

    @Autowired
    private AccountRepository accountRepository;

    @Autowired
    private FreezeRecordRepository freezeRecordRepository;

    @Override
    public boolean tryDebit(String accountId, BigDecimal amount) {
        // 1. 检查账户余额
        Account account = accountRepository.findById(accountId);
        if (account.getBalance().compareTo(amount) < 0) {
            return false;
        }

        // 2. 冻结金额
        account.setBalance(account.getBalance().subtract(amount));
        account.setFrozenAmount(account.getFrozenAmount().add(amount));
        accountRepository.save(account);

        // 3. 记录冻结记录
        FreezeRecord record = new FreezeRecord();
        record.setAccountId(accountId);
        record.setAmount(amount);
        record.setTransactionId(getCurrentTransactionId());
        record.setStatus(FreezeStatus.FROZEN);
        freezeRecordRepository.save(record);

        return true;
    }

    @Override
    public void confirmDebit(String accountId, BigDecimal amount) {
        String transactionId = getCurrentTransactionId();

        // 幂等性检查
        FreezeRecord record = freezeRecordRepository.findByTransactionId(transactionId);
        if (record == null || record.getStatus() == FreezeStatus.CONFIRMED) {
            return;
        }

        // 扣减冻结金额
        Account account = accountRepository.findById(accountId);
        account.setFrozenAmount(account.getFrozenAmount().subtract(amount));
        accountRepository.save(account);

        // 更新冻结记录状态
        record.setStatus(FreezeStatus.CONFIRMED);
        freezeRecordRepository.save(record);
    }

    @Override
    public void cancelDebit(String accountId, BigDecimal amount) {
        String transactionId = getCurrentTransactionId();

        // 幂等性检查
        FreezeRecord record = freezeRecordRepository.findByTransactionId(transactionId);
        if (record == null || record.getStatus() == FreezeStatus.CANCELLED) {
            return;
        }

        // 恢复账户余额
        Account account = accountRepository.findById(accountId);
        account.setBalance(account.getBalance().add(amount));
        account.setFrozenAmount(account.getFrozenAmount().subtract(amount));
        accountRepository.save(account);

        // 更新冻结记录状态
        record.setStatus(FreezeStatus.CANCELLED);
        freezeRecordRepository.save(record);
    }
}

// TCC事务管理器
@Component
public class TccTransactionManager {

    public void executeGlobalTransaction(List<TccParticipant> participants) {
        String globalTransactionId = generateGlobalTransactionId();
        List<TccParticipant> successParticipants = new ArrayList<>();

        try {
            // Try阶段
            for (TccParticipant participant : participants) {
                boolean success = participant.tryExecute(globalTransactionId);
                if (success) {
                    successParticipants.add(participant);
                } else {
                    throw new TccException("Try phase failed for participant: " + participant.getId());
                }
            }

            // Confirm阶段
            for (TccParticipant participant : successParticipants) {
                participant.confirm(globalTransactionId);
            }

        } catch (Exception e) {
            // Cancel阶段
            for (TccParticipant participant : successParticipants) {
                try {
                    participant.cancel(globalTransactionId);
                } catch (Exception cancelException) {
                    log.error("Cancel failed for participant: " + participant.getId(), cancelException);
                    // 记录补偿失败，后续通过定时任务重试
                    recordCompensationFailure(participant, globalTransactionId);
                }
            }
            throw e;
        }
    }
}
```

#### 3.5.3 TCC 优缺点

**优点：**

-   性能较好，没有长期资源锁定
-   支持异步执行
-   最终一致性保证

**缺点：**

-   开发复杂度高，需要实现三个方法
-   业务侵入性强
-   需要考虑幂等性和并发问题

### 3.6 本地消息表

本地消息表通过在业务数据库中存储消息记录，保证本地事务与消息发送的一致性。

#### 3.6.1 实现原理

1. 在同一个本地事务中执行业务操作和消息存储
2. 定时任务扫描消息表，发送未成功的消息
3. 消息消费者处理消息，更新消息状态

```java
// 本地消息表实现
@Service
@Transactional
public class OrderService {

    @Autowired
    private OrderRepository orderRepository;

    @Autowired
    private LocalMessageRepository messageRepository;

    @Autowired
    private MessagePublisher messagePublisher;

    public void createOrder(OrderCreateRequest request) {
        // 1. 创建订单
        Order order = new Order();
        order.setUserId(request.getUserId());
        order.setProductId(request.getProductId());
        order.setAmount(request.getAmount());
        order.setStatus(OrderStatus.PENDING);
        orderRepository.save(order);

        // 2. 在同一事务中保存本地消息
        LocalMessage message = new LocalMessage();
        message.setMessageId(UUID.randomUUID().toString());
        message.setTopic("order-created");
        message.setContent(JsonUtils.toJson(order));
        message.setStatus(MessageStatus.PENDING);
        message.setRetryCount(0);
        message.setCreateTime(new Date());
        messageRepository.save(message);

        // 3. 事务提交后发送消息（通过事务同步器）
        TransactionSynchronizationManager.registerSynchronization(
            new TransactionSynchronizationAdapter() {
                @Override
                public void afterCommit() {
                    messagePublisher.publish(message);
                }
            }
        );
    }
}

// 消息发送器
@Component
public class MessagePublisher {

    @Autowired
    private MessageProducer messageProducer;

    @Autowired
    private LocalMessageRepository messageRepository;

    public void publish(LocalMessage message) {
        try {
            // 发送消息到MQ
            messageProducer.send(message.getTopic(), message.getContent());

            // 更新消息状态为已发送
            message.setStatus(MessageStatus.SENT);
            message.setSendTime(new Date());
            messageRepository.save(message);

        } catch (Exception e) {
            log.error("Failed to publish message: " + message.getMessageId(), e);
            // 发送失败，等待重试任务处理
        }
    }
}

// 消息重试定时任务
@Component
public class MessageRetryTask {

    @Autowired
    private LocalMessageRepository messageRepository;

    @Autowired
    private MessagePublisher messagePublisher;

    @Scheduled(fixedDelay = 60000) // 每分钟执行一次
    public void retryFailedMessages() {
        // 查询待发送和发送失败的消息
        List<LocalMessage> failedMessages = messageRepository.findFailedMessages();

        for (LocalMessage message : failedMessages) {
            if (message.getRetryCount() < 5) { // 最多重试5次
                message.setRetryCount(message.getRetryCount() + 1);
                messageRepository.save(message);

                messagePublisher.publish(message);
            } else {
                // 重试次数超限，标记为失败
                message.setStatus(MessageStatus.FAILED);
                messageRepository.save(message);
                log.error("Message retry exceeded max count: " + message.getMessageId());
            }
        }
    }
}

// 消息消费者
@Component
public class OrderMessageConsumer {

    @Autowired
    private InventoryService inventoryService;

    @RabbitListener(queues = "order-created-queue")
    public void handleOrderCreated(String messageContent) {
        try {
            Order order = JsonUtils.fromJson(messageContent, Order.class);

            // 执行库存扣减
            inventoryService.reduceStock(order.getProductId(), order.getQuantity());

            log.info("Successfully processed order: " + order.getId());

        } catch (Exception e) {
            log.error("Failed to process order message: " + messageContent, e);
            // 消息处理失败，触发重试或进入死信队列
            throw e;
        }
    }
}
```

### 3.7 事务型消息

事务型消息通过消息中间件的特殊机制，保证本地事务与消息发送的一致性。

#### 3.7.1 RocketMQ 事务消息

RocketMQ 通过二阶段提交和事务状态回查机制实现事务消息。

````java
// RocketMQ事务消息生产者
@Component
public class TransactionalMessageProducer {

    private TransactionMQProducer producer;

    @Autowired
    private OrderService orderService;

    @PostConstruct
    public void init() throws MQClientException {
        producer = new TransactionMQProducer("order_producer_group");
        producer.setNamesrvAddr("127.0.0.1:9876");

        // 设置事务监听器
        producer.setTransactionListener(new OrderTransactionListener());
        producer.start();
    }

    public void createOrderWithMessage(OrderCreateRequest request) throws Exception {
        // 构建消息
        Message message = new Message("ORDER_TOPIC", "order_created",
            JsonUtils.toJson(request).getBytes());

        // 发送事务消息
        SendResult sendResult = producer.sendMessageInTransaction(message, request);
        log.info("Transaction message sent: " + sendResult.getTransactionId());
    }
}

// 事务消息监听器
public class OrderTransactionListener implements TransactionListener {

    @Autowired
    private OrderService orderService;

    @Override
    public LocalTransactionState executeLocalTransaction(Message message, Object arg) {
        try {
            OrderCreateRequest request = (OrderCreateRequest) arg;

            // 执行本地事务
            orderService.createOrder(request);

            return LocalTransactionState.COMMIT_MESSAGE;

        } catch (Exception e) {
            log.error("Local transaction failed", e);
            return LocalTransactionState.ROLLBACK_MESSAGE;
        }
    }

    @Override
    public LocalTransactionState checkLocalTransaction(MessageExt messageExt) {
        try {
            // 根据消息内容检查本地事务状态
            String content = new String(messageExt.getBody());
            OrderCreateRequest request = JsonUtils.fromJson(content, OrderCreateRequest.class);

            // 查询订单是否创建成功
            Order order = orderService.findOrderByRequest(request);
            if (order != null) {
                return LocalTransactionState.COMMIT_MESSAGE;
            } else {
                return LocalTransactionState.ROLLBACK_MESSAGE;
            }

        } catch (Exception e) {
            log.error("Check local transaction failed", e);
            return LocalTransactionState.UNKNOW;
        }
    }
}

// 事务消息消费者
@Component
public class TransactionalMessageConsumer {

    @Autowired
    private InventoryService inventoryService;

    @PostConstruct
    public void init() throws MQClientException {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("inventory_consumer_group");
        consumer.setNamesrvAddr("127.0.0.1:9876");
## 第八章 常见面试问题解析

### 8.1 核心概念问题

#### 8.1.1 什么是分布式事务？有哪些实现方案？

**回答要点：**

在分布式系统中，一次业务处理可能需要多个应用来实现，比如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存。对于此下单操作，订单创建与减库存应该是要同时成功或同时失败的，但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败。解决这类问题，就需要用到分布式事务。

**常用解决方案：**

1. **本地消息表**
   - 实现原理：创建订单时，将减库存消息在本地事务中一起提交到数据库存入本地消息表，然后调用库存系统
   - 容错机制：如果调用库存系统失败，则由后台定时任务从本地消息表中取出未成功的消息，重试调用库存系统

2. **事务型消息（RocketMQ事务消息）**
   - a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者不可见
   - b. 创建订单，根据创建订单成功与否，向Broker发送commit或rollback
   - c. 生产者还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口查询订单是否创建成功
   - d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束

3. **Seata框架**
   - 阿里开源的分布式事务框架，支持AT、TCC、SAGA、XA多种模式
   - 底层都是基于两阶段提交理论来实现的

#### 8.1.2 什么是CAP理论？

**回答要点：**

CAP理论是分布式领域中非常重要的一个指导理论：
- **C（Consistency）**：强一致性，所有用户看到的数据是一样的
- **A（Availability）**：可用性，总能找到一个可用的数据副本
- **P（Partition Tolerance）**：分区容错性，能够容忍网络中断等故障

**核心观点：**
CAP理论指出在目前的硬件条件下，一个分布式系统必须要保证分区容错性（P），而在这个前提下，分布式系统要么保证CP，要么保证AP，无法同时保证CAP。

**具体说明：**
- 分区容错性表示，一个系统虽然是分布式的，但是对外看上去应该是一个整体，不能由于分布式系统内部的某个节点挂掉，或网络出现了故障，而导致系统对外出现异常
- 强一致性表示，一个分布式系统中各个节点之间能及时的同步数据，在数据同步过程中，是不能对外提供服务的，不然就会造成数据不一致
- 可用性表示，一个分布式系统对外要保证可用

#### 8.1.3 什么是BASE理论？

**回答要点：**

由于不能同时满足CAP，所以出现了BASE理论。BASE理论是对CAP理论的延伸，提供了更实用的设计指导。

**BASE含义：**
1. **BA**：`Basically Available`（基本可用）
   - 表示可以允许一定程度的不可用
   - 比如由于系统故障，请求时间变长，或者由于系统故障导致部分非核心功能不可用，都是允许的

2. **S**：`Soft State`（软状态）
   - 表示分布式系统可以处于一种中间状态，比如数据正在同步
   - 允许系统在不同节点的数据副本之间进行数据同步的过程存在延时

3. **E**：`Eventually Consistent`（最终一致性）
   - 表示最终一致性，不要求分布式系统数据实时达到一致
   - 允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的

### 8.2 技术实现问题

#### 8.2.1 分布式ID是什么？有哪些解决方案？

**回答要点：**

在开发中，我们通常会需要一个唯一ID来标识数据，如果是单体架构，我们可以通过数据库的主键，或直接在内存中维护一个自增数字来作为ID都是可以的，但对于一个分布式系统，就会有可能会出现ID冲突，此时有以下解决方案：

**主要解决方案：**

1. **UUID**
   - 优点：实现简单，复杂度最低
   - 缺点：会影响存储空间和性能，长度较长，无序性

2. **数据库自增主键**
   - 优点：复杂度适中，ID长度较UUID更短
   - 缺点：受到单机数据库性能的限制，并发量大的时候不是最优方案

3. **Redis/ZooKeeper特性生成**
   - 利用Redis的自增命令、ZooKeeper的顺序节点
   - 性能比单机数据库有所提高，可以适当选用

4. **雪花算法**
   - 优点：性能高，趋势递增，满足分布式要求
   - 底层原理：通过某台机器在某一毫秒内对某一个数字自增
   - 业界存在`TinyID`、`Leaf`等开源中间件实现了雪花算法

#### 8.2.2 分布式锁的使用场景是什么？有哪些实现方案？

**回答要点：**

**使用场景分析：**
在单体架构中，多个线程都是属于同一个进程的，所以在线程并发执行时，遇到资源竞争时，可以利用`ReentrantLock`、`synchronized`等技术来作为锁，来控制共享资源的使用。

分布式架构中，多个线程是可能处于不同进程中的，而这些线程并发执行遇到资源竞争时，利用`ReentrantLock`、`synchronized`等技术是没办法来控制多个进程中的线程的，所以需要分布式锁。

**主要实现方案：**

1. **ZooKeeper分布式锁**
   - 利用ZooKeeper的临时节点、顺序节点、watch机制来实现
   - 特点：高一致性，因为ZooKeeper保证的是CP，所以由它实现的分布式锁更可靠，不会出现混乱
   - 适用场景：对一致性要求极高的场景

2. **Redis分布式锁**
   - 利用Redis的setnx、lua脚本、发布订阅等机制来实现
   - 特点：高可用，因为Redis保证的是AP，所以由它实现的分布式锁性能更好
   - 注意：可能不够可靠，不稳定（一旦Redis中的数据出现了不一致），可能会出现多个客户端同时获得锁的情况

### 8.3 数据一致性问题

#### 8.3.1 数据一致性模型有哪些？

**回答要点：**

**主要一致性模型：**

1. **强一致性**
   - 当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新过的值
   - 这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么
   - 根据CAP理论，这种实现需要牺牲可用性

2. **弱一致性**
   - 系统在数据写入成功之后，不承诺立即可以读到最新写入的值
   - 也不会具体的承诺多久之后可以读到
   - 用户读到某一操作对系统数据的更新需要一段时间，我们称这段时间为"不一致性窗口"

3. **最终一致性**
   - 最终一致性是弱一致性的特例，强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态
   - 最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性

**最终一致性的细分类型：**

- **因果一致性**：要求有因果关系的操作顺序得到保证
- **读己之所写**：进程A更新一项数据后，它自己总是能访问到自己更新过的最新值
- **会话一致性**：将数据一致性框定在会话当中，在一个会话当中实现读己之所写的一致性
- **单调读一致性**：如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值
- **单调写一致性**：一个系统需要保证来自同一个进程的写操作被顺序执行

#### 8.3.2 选举算法Quorum机制、WARO

**回答要点：**

**WARO协议：**
- WARO：一种简单的副本控制协议，写操作时、只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败
- 优先保证读，任何节点读到的数据都是最新数据
- 牺牲了更新服务的可用性，只要有一个副本故障了，写服务就不会成功
- 但只要有一个节点存活，仍能提供读服务

**Quorum机制：**
- 基本原理：比如10个副本，一次成功更新了3个，那么至少需要读取8个副本的数据，可以保证读到了最新的数据
- 无法保证强一致性，也就是无法实现任何时刻任何用户或节点都可以读到最近一次成功提交的副本数据
- 需要配合一个获取最新成功提交的版本号的metadata服务，这样可以确定最新已经成功提交的版本号，然后从已经读到的数据中就可以确认最新写入的数据

### 8.4 协议对比问题

#### 8.4.1 说一下两阶段提交和三阶段提交的过程？分别有什么问题？

**两阶段提交协议（2PC）：**

**执行过程：**
1. **第一阶段（投票阶段）**：
   - 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应
   - 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志
   - 各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个"同意"消息；如果参与者节点的事务操作实际执行失败，则它返回一个"中止"消息

2. **第二阶段（提交执行阶段）**：
   - 当协调者节点从所有参与者节点获得的相应消息都为"同意"时：
     - 协调者节点向所有参与者节点发出"正式提交(commit)"的请求
     - 参与者节点正式完成操作，并释放在整个事务期间内占用的资源
     - 参与者节点向协调者节点发送"完成"消息
     - 协调者节点受到所有参与者节点反馈的"完成"消息后，完成事务

**两阶段提交存在的问题：**
1. 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态
2. 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败
3. 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错
4. 二阶段无法解决的问题：协调者在发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交

**三阶段提交协议（3PC）：**

**改动点：**
1. 引入超时机制。同时在协调者和参与者中都引入超时机制
2. 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的

**执行过程：**
3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。

1. **CanCommit阶段**：
   - 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作
   - 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No

2. **PreCommit阶段**：
   - 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行
   - 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断

3. **DoCommit阶段**：
   - 该阶段进行真正的事务提交，也可以分为执行提交和中断事务两种情况

**三阶段提交的问题：**
网络分区可能会带来问题。需要四阶段解决：四阶段直接调用远程服务的数据状态，确定当前数据一致性的情况。





## 第五章 分布式一致性算法

### 5.1 数据一致性模型

#### 5.1.1 强一致性
当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新过的值。这种模式对用户最友好，但根据CAP理论，实现强一致性需要牺牲可用性。

```java
// 强一致性示例：分布式锁保证数据一致性
@Service
public class StrongConsistencyService {

    @Autowired
    private RedisTemplate<String, String> redisTemplate;

    @Autowired
    private DataRepository dataRepository;

    public void updateDataWithStrongConsistency(String dataId, String newValue) {
        String lockKey = "lock:data:" + dataId;

        // 获取分布式锁
        String lockValue = UUID.randomUUID().toString();
        Boolean acquired = redisTemplate.opsForValue()
            .setIfAbsent(lockKey, lockValue, Duration.ofSeconds(30));

        if (Boolean.TRUE.equals(acquired)) {
            try {
                // 更新数据
                Data data = dataRepository.findById(dataId);
                data.setValue(newValue);
                dataRepository.save(data);

                // 同步到所有副本
                syncToAllReplicas(data);

            } finally {
                // 释放锁
                releaseLock(lockKey, lockValue);
            }
        } else {
            throw new ConcurrentUpdateException("数据正在被其他进程更新");
        }
    }
}
````

#### 5.1.2 弱一致性

系统在数据写入成功后，不承诺立即可以读到最新写入的值，也不承诺多久之后可以读到。用户读到某一操作对系统数据的更新需要一段时间，这段时间称为"不一致性窗口"。

#### 5.1.3 最终一致性

最终一致性是弱一致性的特例，强调所有数据副本在经过一段时间的同步后，最终都能够达到一致的状态。

**最终一致性类型详解：**

1. **因果一致性（Causal Consistency）**

```java
// 因果一致性示例：评论系统
@Service
public class CommentService {

    public void replyToComment(Long parentCommentId, String replyContent, String userId) {
        // 确保回复评论在父评论之后显示
        Comment parentComment = commentRepository.findById(parentCommentId);

        Comment reply = new Comment();
        reply.setParentId(parentCommentId);
        reply.setContent(replyContent);
        reply.setUserId(userId);
        reply.setCreateTime(new Date());
        // 确保回复时间晚于父评论
        reply.setCausalTimestamp(parentComment.getCausalTimestamp() + 1);

        commentRepository.save(reply);
    }
}
```

2. **会话一致性（Session Consistency）**

```java
// 会话一致性示例：购物车系统
@Service
public class ShoppingCartService {

    @Autowired
    private CartRepository cartRepository;

    @Autowired
    private CacheManager cacheManager;

    public void addToCart(String sessionId, Long productId, Integer quantity) {
        // 在会话内保证一致性
        Cart cart = getCartFromSession(sessionId);
        cart.addItem(productId, quantity);

        // 更新会话缓存
        cacheManager.put("cart:" + sessionId, cart);

        // 异步更新数据库
        cartRepository.saveAsync(cart);
    }

    public Cart getCart(String sessionId) {
        // 在同一会话中，总是能读到自己的更新
        return cacheManager.get("cart:" + sessionId, Cart.class);
    }
}
```

### 5.2 Quorum 机制

Quorum 机制通过要求操作获得大多数节点的确认来保证数据一致性。

#### 5.2.1 Quorum 读写

-   **写操作**：至少获得 W 个节点的确认才算成功
-   **读操作**：至少从 R 个节点读取数据
-   **一致性保证**：当 W + R > N 时，能保证读到最新数据

```java
// Quorum机制实现示例
@Service
public class QuorumStorage {

    private List<StorageNode> nodes;
    private int totalNodes;
    private int writeQuorum;
    private int readQuorum;

    public QuorumStorage(List<StorageNode> nodes) {
        this.nodes = nodes;
        this.totalNodes = nodes.size();
        this.writeQuorum = totalNodes / 2 + 1; // 大多数
        this.readQuorum = totalNodes / 2 + 1;
    }

    public boolean write(String key, String value, long version) {
        List<CompletableFuture<Boolean>> futures = new ArrayList<>();

        // 并行写入所有节点
        for (StorageNode node : nodes) {
            CompletableFuture<Boolean> future = CompletableFuture.supplyAsync(() -> {
                try {
                    return node.write(key, value, version);
                } catch (Exception e) {
                    log.error("Write to node {} failed", node.getId(), e);
                    return false;
                }
            });
            futures.add(future);
        }

        // 等待writeQuorum个节点确认
        int successCount = 0;
        for (CompletableFuture<Boolean> future : futures) {
            try {
                if (future.get(1, TimeUnit.SECONDS)) {
                    successCount++;
                    if (successCount >= writeQuorum) {
                        return true;
                    }
                }
            } catch (Exception e) {
                log.error("Write operation failed", e);
            }
        }

        return false;
    }

    public String read(String key) {
        List<CompletableFuture<VersionedValue>> futures = new ArrayList<>();

        // 并行从所有节点读取
        for (StorageNode node : nodes) {
            CompletableFuture<VersionedValue> future = CompletableFuture.supplyAsync(() -> {
                try {
                    return node.read(key);
                } catch (Exception e) {
                    log.error("Read from node {} failed", node.getId(), e);
                    return null;
                }
            });
            futures.add(future);
        }

        // 收集readQuorum个读取结果
        List<VersionedValue> values = new ArrayList<>();
        for (CompletableFuture<VersionedValue> future : futures) {
            try {
                VersionedValue value = future.get(1, TimeUnit.SECONDS);
                if (value != null) {
                    values.add(value);
                    if (values.size() >= readQuorum) {
                        break;
                    }
                }
            } catch (Exception e) {
                log.error("Read operation failed", e);
            }
        }

        // 返回版本号最高的值
        return values.stream()
            .max(Comparator.comparing(VersionedValue::getVersion))
            .map(VersionedValue::getValue)
            .orElse(null);
    }
}
```

### 5.3 WARO 协议

WARO（Write All, Read One）是一种简单的副本控制协议。

#### 5.3.1 WARO 特点

-   **写操作**：只有当所有副本都更新成功后，写操作才算成功
-   **读操作**：从任意一个副本读取即可
-   **优先保证读性能**：任何节点读到的数据都是最新的
-   **牺牲写可用性**：只要有一个副本故障，写服务就会失败

```java
// WARO协议实现示例
@Service
public class WaroStorage {

    private List<StorageNode> replicas;

    public boolean write(String key, String value) {
        List<CompletableFuture<Boolean>> futures = new ArrayList<>();

        // 写入所有副本
        for (StorageNode replica : replicas) {
            CompletableFuture<Boolean> future = CompletableFuture.supplyAsync(() -> {
                try {
                    return replica.write(key, value);
                } catch (Exception e) {
                    log.error("Write to replica {} failed", replica.getId(), e);
                    return false;
                }
            });
            futures.add(future);
        }

        // 等待所有副本写入成功
        try {
            CompletableFuture<Void> allWrites = CompletableFuture.allOf(
                futures.toArray(new CompletableFuture[0]));
            allWrites.get(5, TimeUnit.SECONDS);

            // 检查是否所有写入都成功
            return futures.stream().allMatch(future -> {
                try {
                    return future.get();
                } catch (Exception e) {
                    return false;
                }
            });
        } catch (Exception e) {
            log.error("WARO write operation failed", e);
            return false;
        }
    }

    public String read(String key) {
        // 从任意一个可用的副本读取
        for (StorageNode replica : replicas) {
            try {
                String value = replica.read(key);
                if (value != null) {
                    return value;
                }
            } catch (Exception e) {
                log.warn("Read from replica {} failed, trying next", replica.getId());
            }
        }
        return null;
    }
}
```

### 5.4 分布式 ID 生成方案

在分布式系统中，需要全局唯一的 ID 来标识数据。

#### 5.4.1 UUID 方案

```java
// UUID生成器
@Component
public class UuidGenerator {

    public String generateId() {
        return UUID.randomUUID().toString().replace("-", "");
    }
}
```

**优点**：实现简单，性能好
**缺点**：长度较长（32 位），无序性，存储空间大

#### 5.4.2 数据库自增 ID

```java
// 数据库自增ID生成器
@Service
public class DatabaseIdGenerator {

    @Autowired
    private IdGeneratorRepository repository;

    public synchronized Long generateId(String bizType) {
        IdGenerator generator = repository.findByBizType(bizType);
        if (generator == null) {
            generator = new IdGenerator();
            generator.setBizType(bizType);
            generator.setCurrentId(1L);
        } else {
            generator.setCurrentId(generator.getCurrentId() + 1);
        }
        repository.save(generator);
        return generator.getCurrentId();
    }
}
```

#### 5.4.3 雪花算法

```java
// 雪花算法实现
@Component
public class SnowflakeIdGenerator {

    private static final long START_TIMESTAMP = 1609459200000L; // 2021-01-01
    private static final long SEQUENCE_BIT = 12;
    private static final long MACHINE_BIT = 5;
    private static final long DATACENTER_BIT = 5;

    private static final long MAX_DATACENTER_NUM = -1L ^ (-1L << DATACENTER_BIT);
    private static final long MAX_MACHINE_NUM = -1L ^ (-1L << MACHINE_BIT);
    private static final long MAX_SEQUENCE = -1L ^ (-1L << SEQUENCE_BIT);

    private static final long MACHINE_LEFT = SEQUENCE_BIT;
    private static final long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT;
    private static final long TIMESTAMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT;

    private long datacenterId;
    private long machineId;
    private long sequence = 0L;
    private long lastTimestamp = -1L;

    public SnowflakeIdGenerator(long datacenterId, long machineId) {
        if (datacenterId > MAX_DATACENTER_NUM || datacenterId < 0) {
            throw new IllegalArgumentException("datacenterId can't be greater than MAX_DATACENTER_NUM or less than 0");
        }
        if (machineId > MAX_MACHINE_NUM || machineId < 0) {
            throw new IllegalArgumentException("machineId can't be greater than MAX_MACHINE_NUM or less than 0");
        }
        this.datacenterId = datacenterId;
        this.machineId = machineId;
    }

    public synchronized long nextId() {
        long currTimestamp = getCurrentTimestamp();

        if (currTimestamp < lastTimestamp) {
            throw new RuntimeException("Clock moved backwards. Refusing to generate id");
        }

        if (currTimestamp == lastTimestamp) {
            sequence = (sequence + 1) & MAX_SEQUENCE;
            if (sequence == 0L) {
                currTimestamp = getNextTimestamp();
            }
        } else {
            sequence = 0L;
        }

        lastTimestamp = currTimestamp;

        return (currTimestamp - START_TIMESTAMP) << TIMESTAMP_LEFT
                | datacenterId << DATACENTER_LEFT
                | machineId << MACHINE_LEFT
                | sequence;
    }

    private long getNextTimestamp() {
        long timestamp = getCurrentTimestamp();
        while (timestamp <= lastTimestamp) {
            timestamp = getCurrentTimestamp();
        }
        return timestamp;
    }

    private long getCurrentTimestamp() {
        return System.currentTimeMillis();
    }
}
```

## 第六章 分布式锁

### 6.1 分布式锁概述

#### 6.1.1 分布式锁的必要性

在单体应用中，可以使用`synchronized`、`ReentrantLock`等机制来控制共享资源的访问。但在分布式环境中，这些机制无法跨 JVM 工作，因此需要分布式锁来协调不同节点对共享资源的访问。

#### 6.1.2 分布式锁与分布式事务的区别

| 特性       | 分布式锁               | 分布式事务             |
| ---------- | ---------------------- | ---------------------- |
| 解决问题   | 分布式资源抢占问题     | 流程化操作的原子性问题 |
| 应用场景   | 防止重复执行、资源互斥 | 保证多个操作的原子性   |
| 实现复杂度 | 相对简单               | 相对复杂               |
| 性能影响   | 较小                   | 较大                   |

### 6.2 基于 Redis 的分布式锁

#### 6.2.1 Redis 分布式锁特点

-   **高可用性**：Redis 保证 AP（可用性和分区容错性）
-   **高性能**：Redis 的高性能特性适合分布式锁场景
-   **实现相对简单**：基于 Redis 的原子操作

#### 6.2.2 Redis 分布式锁实现

```java
// Redis分布式锁实现
@Component
public class RedisDistributedLock {

    @Autowired
    private RedisTemplate<String, String> redisTemplate;

    // Lua脚本，保证释放锁的原子性
    private static final String UNLOCK_SCRIPT =
        "if redis.call('get', KEYS[1]) == ARGV[1] then " +
        "    return redis.call('del', KEYS[1]) " +
        "else " +
        "    return 0 " +
        "end";

    private static final String RENEW_SCRIPT =
        "if redis.call('get', KEYS[1]) == ARGV[1] then " +
        "    return redis.call('expire', KEYS[1], ARGV[2]) " +
        "else " +
        "    return 0 " +
        "end";

    /**
     * 尝试获取锁
     * @param lockKey 锁的key
     * @param lockValue 锁的值（用于校验锁的所有者）
     * @param expireTime 锁的过期时间（毫秒）
     * @return 是否获取成功
     */
    public boolean tryLock(String lockKey, String lockValue, long expireTime) {
        Boolean result = redisTemplate.opsForValue()
            .setIfAbsent(lockKey, lockValue, Duration.ofMillis(expireTime));
        return Boolean.TRUE.equals(result);
    }

    /**
     * 释放锁
     * @param lockKey 锁的key
     * @param lockValue 锁的值
     * @return 是否释放成功
     */
    public boolean unlock(String lockKey, String lockValue) {
        DefaultRedisScript<Long> script = new DefaultRedisScript<>();
        script.setScriptText(UNLOCK_SCRIPT);
        script.setResultType(Long.class);

        Long result = redisTemplate.execute(script,
            Collections.singletonList(lockKey), lockValue);
        return result != null && result > 0;
    }

    /**
     * 续租锁
     * @param lockKey 锁的key
     * @param lockValue 锁的值
     * @param expireTime 新的过期时间（秒）
     * @return 是否续租成功
     */
    public boolean renewLock(String lockKey, String lockValue, int expireTime) {
        DefaultRedisScript<Long> script = new DefaultRedisScript<>();
        script.setScriptText(RENEW_SCRIPT);
        script.setResultType(Long.class);

        Long result = redisTemplate.execute(script,
            Collections.singletonList(lockKey), lockValue, String.valueOf(expireTime));
        return result != null && result > 0;
    }
}

// 带重试和自动续租的分布式锁
@Component
public class AdvancedRedisLock {

    @Autowired
    private RedisDistributedLock redisLock;

    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);

    /**
     * 获取锁，支持重试和自动续租
     */
    public boolean lockWithRetry(String lockKey, long expireTime, long retryInterval,
                                int maxRetryTimes, Consumer<String> business) {
        String lockValue = UUID.randomUUID().toString();
        int retryTimes = 0;

        while (retryTimes < maxRetryTimes) {
            if (redisLock.tryLock(lockKey, lockValue, expireTime)) {
                // 获取锁成功，启动自动续租
                ScheduledFuture<?> renewTask = startAutoRenew(lockKey, lockValue, expireTime);

                try {
                    // 执行业务逻辑
                    business.accept(lockValue);
                    return true;
                } finally {
                    // 停止续租任务
                    renewTask.cancel(true);
                    // 释放锁
                    redisLock.unlock(lockKey, lockValue);
                }
            }

            // 获取锁失败，等待后重试
            try {
                Thread.sleep(retryInterval);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                return false;
            }
            retryTimes++;
        }

        return false;
    }

    /**
     * 启动自动续租任务
     */
    private ScheduledFuture<?> startAutoRenew(String lockKey, String lockValue, long expireTime) {
        return scheduler.scheduleAtFixedRate(() -> {
            try {
                boolean renewed = redisLock.renewLock(lockKey, lockValue, (int) (expireTime / 1000));
                if (!renewed) {
                    log.warn("Failed to renew lock: {}", lockKey);
                }
            } catch (Exception e) {
                log.error("Error renewing lock: " + lockKey, e);
            }
        }, expireTime / 3, expireTime / 3, TimeUnit.MILLISECONDS);
    }
}

// 使用示例
@Service
public class OrderService {

    @Autowired
    private AdvancedRedisLock distributedLock;

    public void processOrder(Long orderId) {
        String lockKey = "order:lock:" + orderId;

        boolean locked = distributedLock.lockWithRetry(
            lockKey,
            30000, // 锁过期时间30秒
            100,   // 重试间隔100ms
            50,    // 最大重试50次
            (lockValue) -> {
                // 业务逻辑
                doProcessOrder(orderId);
            }
        );

        if (!locked) {
            throw new BusinessException("获取订单处理锁失败");
        }
    }

    private void doProcessOrder(Long orderId) {
        // 具体的订单处理逻辑
        log.info("Processing order: {}", orderId);
        // ... 业务逻辑
    }
}
```

### 6.3 基于 ZooKeeper 的分布式锁

#### 6.3.1 ZooKeeper 分布式锁特点

-   **强一致性**：ZooKeeper 保证 CP（一致性和分区容错性）
-   **可靠性高**：不会出现锁被误删的情况
-   **支持阻塞等待**：通过 Watch 机制实现阻塞等待

#### 6.3.2 ZooKeeper 分布式锁实现

```java
// ZooKeeper分布式锁实现
@Component
public class ZookeeperDistributedLock {

    private ZooKeeper zooKeeper;
    private static final String LOCK_ROOT_PATH = "/distributed-locks";

    @PostConstruct
    public void init() throws Exception {
        zooKeeper = new ZooKeeper("localhost:2181", 30000, event -> {
            // 处理连接事件
            log.info("ZooKeeper connection event: {}", event);
        });

        // 创建锁根目录
        if (zooKeeper.exists(LOCK_ROOT_PATH, false) == null) {
            zooKeeper.create(LOCK_ROOT_PATH, new byte[0],
                ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
    }

    /**
     * 获取分布式锁
     */
    public ZkLock lock(String lockName, long timeoutMs) throws Exception {
        String lockPath = LOCK_ROOT_PATH + "/" + lockName;

        // 创建锁目录
        if (zooKeeper.exists(lockPath, false) == null) {
            zooKeeper.create(lockPath, new byte[0],
                ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }

        // 创建临时顺序节点
        String currentNode = zooKeeper.create(
            lockPath + "/lock-",
            Thread.currentThread().getName().getBytes(),
            ZooDefs.Ids.OPEN_ACL_UNSAFE,
            CreateMode.EPHEMERAL_SEQUENTIAL
        );

        return new ZkLock(lockName, currentNode, timeoutMs);
    }

    /**
     * ZooKeeper锁对象
     */
    public class ZkLock implements AutoCloseable {
        private String lockName;
        private String currentNode;
        private String currentNodeName;
        private boolean locked = false;

        public ZkLock(String lockName, String currentNode, long timeoutMs) throws Exception {
            this.lockName = lockName;
            this.currentNode = currentNode;
            this.currentNodeName = currentNode.substring(currentNode.lastIndexOf("/") + 1);

            // 尝试获取锁
            this.locked = tryAcquireLock(timeoutMs);
        }

        private boolean tryAcquireLock(long timeoutMs) throws Exception {
            long startTime = System.currentTimeMillis();

            while (System.currentTimeMillis() - startTime < timeoutMs) {
                List<String> children = zooKeeper.getChildren(LOCK_ROOT_PATH + "/" + lockName, false);
                Collections.sort(children);

                // 如果当前节点是最小的节点，则获得锁
                if (currentNodeName.equals(children.get(0))) {
                    return true;
                }

                // 找到前一个节点，并监听它的删除事件
                String prevNode = null;
                for (int i = 0; i < children.size(); i++) {
                    if (currentNodeName.equals(children.get(i))) {
                        if (i > 0) {
                            prevNode = children.get(i - 1);
                        }
                        break;
                    }
                }

                if (prevNode != null) {
                    final CountDownLatch latch = new CountDownLatch(1);
                    String prevNodePath = LOCK_ROOT_PATH + "/" + lockName + "/" + prevNode;

                    Stat stat = zooKeeper.exists(prevNodePath, event -> {
                        if (Watcher.Event.EventType.NodeDeleted.equals(event.getType())) {
                            latch.countDown();
                        }
                    });

                    // 如果前一个节点已经不存在，继续循环
                    if (stat == null) {
                        continue;
                    }

                    // 等待前一个节点删除
                    long remainTime = timeoutMs - (System.currentTimeMillis() - startTime);
                    if (remainTime > 0) {
                        latch.await(remainTime, TimeUnit.MILLISECONDS);
                    }
                }
            }

            return false;
        }

        public boolean isLocked() {
            return locked;
        }

        @Override
        public void close() throws Exception {
            if (currentNode != null) {
                try {
                    zooKeeper.delete(currentNode, -1);
                } catch (KeeperException.NoNodeException e) {
                    // 节点已经不存在，忽略
                }
            }
        }
    }
}

// 使用示例
@Service
public class ZkLockService {

    @Autowired
    private ZookeeperDistributedLock zkLock;

    public void processWithLock(String resourceId) {
        try (ZookeeperDistributedLock.ZkLock lock = zkLock.lock("resource-" + resourceId, 30000)) {
            if (lock.isLocked()) {
                // 执行需要加锁的业务逻辑
                doProcess(resourceId);
            } else {
                throw new BusinessException("获取锁超时");
            }
        } catch (Exception e) {
            log.error("处理业务失败", e);
            throw new RuntimeException(e);
        }
    }

    private void doProcess(String resourceId) {
        log.info("Processing resource: {}", resourceId);
        // 业务逻辑
    }
}
```

### 6.4 分布式锁选型对比

| 特性       | Redis 分布式锁                       | ZooKeeper 分布式锁     |
| ---------- | ------------------------------------ | ---------------------- |
| 一致性保证 | AP（最终一致性）                     | CP（强一致性）         |
| 性能       | 高                                   | 相对较低               |
| 可靠性     | 可能存在锁失效                       | 高可靠                 |
| 实现复杂度 | 中等                                 | 相对复杂               |
| 运维复杂度 | 低                                   | 高                     |
| 锁等待方式 | 轮询                                 | 事件通知（Watch）      |
| 适用场景   | 对性能要求高，可容忍极低概率的锁失效 | 对一致性要求极高的场景 |

### 6.5 分布式锁使用场景

#### 6.5.1 防止重复执行

```java
@Service
public class PaymentService {

    @Autowired
    private RedisDistributedLock distributedLock;

    public void processPayment(String orderId) {
        String lockKey = "payment:lock:" + orderId;
        String lockValue = UUID.randomUUID().toString();

        if (distributedLock.tryLock(lockKey, lockValue, 30000)) {
            try {
                // 检查订单是否已经支付
                if (isOrderPaid(orderId)) {
                    log.info("Order {} has already been paid", orderId);
                    return;
                }

                // 执行支付逻辑
                doPayment(orderId);

            } finally {
                distributedLock.unlock(lockKey, lockValue);
            }
        } else {
            log.warn("Failed to acquire payment lock for order: {}", orderId);
        }
    }
}
```

#### 6.5.2 资源互斥访问

```java
@Service
public class InventoryService {

    @Autowired
    private ZookeeperDistributedLock zkLock;

    public boolean reduceStock(Long productId, int quantity) {
        String lockKey = "inventory:" + productId;

        try (ZookeeperDistributedLock.ZkLock lock = zkLock.lock(lockKey, 5000)) {
            if (!lock.isLocked()) {
                return false;
            }

            // 获取当前库存
            int currentStock = getCurrentStock(productId);

            if (currentStock >= quantity) {
                // 扣减库存
                updateStock(productId, currentStock - quantity);
                return true;
            } else {
                return false;
            }

        } catch (Exception e) {
            log.error("减库存操作失败", e);
            return false;
        }
    }
}
```

## 什么是分布式事务？有哪些实现方案？

在分布式系统中，一次业务处理可能需要多个应用来实现，比如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存，而对于次下单，订单创建与减库存应该是要同时成功或同时失败的，但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败，那么解决这类问题，就需要用到分布式事务。

常用解决方案有：

1. 本地消息表：创建订单时，将减库存消息加入在本地事务中，一起提交到数据库存入本地消息表，然后调用库存系统，如果调用成功则修改本地消息状态为成功，如果调用库存系统失败，则由后台定时任务从本地消息表中取出未成功的消息，重试调用库存系统
2. 消息队列：目前 RocketMQ 中支持事务消息，它的工作原理是：
   a.生产者订单系统先发送一条 half 消息到 Broker，half 消息对消费者而言是不可见的
   b.再创建订单，根据创建订单成功与否，向 Broker 发送 commit 或 rollback
   c.并且生产者订单系统还可以提供 Broker 回调接口，当 Broker 发现一段时间 half 消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
   d.一旦 half 消息 commit 了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
   e.如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理
3. Seata：阿里开源的分布式事务框架，支持 AT、TCC 等多种模式，底层都是基于两阶段提交理论来实现的

## 数据一致性模型有哪些

-   强一致性：当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新过的值，这种是对用户最友好的，就是用户上一次写什么，下一次就保证能读到什么。根据 CAP 理论，这种实现需要性可用性。
-   弱一致性：系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到用户读到某一操作对系统数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
-   最终一致性：最终一致性是弱一致性的特例，强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态
    因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。到达最终一致性的时间，就是不一致窗口时间，在没有故障发生的前提下，不一致窗口的时间主要受通信延，系统负载和复制副本的个数影响，最终一致性模型根据其提供的不同保证可以划分为更多的模型，包括因果一致性和会话一致性等
-   因果一致性：要求有因果关系的操作顺序得到保证
    非因果关系的操作顺序则无所谓进程 A 在更新完某个数据项后通知了进程 B，那么进程 B 之后对该数据项的访问都应该能够获取到进程 A 更新后的最新值，并且如果进程 B 要对该数据项进行更新操作的话，务必基于进程 A 更新后的最新值
    在微博或者微信进行评论的时候，比如你在朋友圈发了一张照片，朋友给你评论了，而你对朋友的评论进行了回复，这条朋友圈的显示中，你的回复必须在朋友之后，这是一个因果关系，而其他没有因果关系的数据，可以允许不一致
-   会话一致性：将对系统数据的访问过程框定在了一个会话当中，约定了系统能保证在同一个有效的会话中实现读己之所写的一致性，就是在你的一次访问中，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。实际开发中有分布式的 Session 一致性问题，可以认为是会话一致性的一个应用

## 选举算法 Quorum 机制、 WARO

-   Waro：一种简单的副本控制协议，写操作时、只有当所有的副本都更新成功之后，这次写操作才算成功，否则视为失败
    优先保证读、任何节点读到的数据都是最新数据，性了更新服务的可用性、只要有一个副本岩机了，写服务就不会成功。但只要有一个节点存活、仍能提供读服务
-   Quorum 机制：10 个副本，一次成功更新了三个，那么至少需要读取八个副本的数据，可以保证读到了最新的数据
    无法保证强一致性，也就是无法实现任何时刻任何用户或节点都可以读到最近一次成功提交的副本数据。需要配合一个获取最新成功提交的版本号的 metadata 服务，这样可以确定最新已经成功提交的版本号，然后从已经读到的数据中就可以确认最新写入的数据

## 第四章 Seata 分布式事务框架

### 4.1 Seata 简介

Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 提供了 AT、TCC、SAGA 和 XA 四种事务模式，其中 AT 和 TCC 模式在生产环境中应用最为广泛。

### 4.2 Seata 架构

#### 4.2.1 三大核心组件

**TC（Transaction Coordinator）- 事务协调者**

-   维护全局和分支事务的状态
-   驱动全局事务提交或回滚
-   负责事务 ID 的生成、注册、提交、回滚等

**TM（Transaction Manager）- 事务管理者**

-   定义全局事务的范围
-   开始全局事务、提交或回滚全局事务

**RM（Resource Manager）- 资源管理者**

-   管理分支事务处理的资源
-   与 TC 交互注册分支事务和报告分支事务状态
-   驱动分支事务提交或回滚

#### 4.2.2 Seata 执行流程

```java
// Seata全局事务执行流程示例
@GlobalTransactional(name = "create-order", rollbackFor = Exception.class)
public void createOrder(OrderDTO orderDTO) {
    // 1. TM开启全局事务
    log.info("Starting global transaction");

    // 2. 创建订单（RM1注册分支事务）
    Order order = orderService.createOrder(orderDTO);

    // 3. 扣减库存（RM2注册分支事务）
    inventoryService.reduceStock(orderDTO.getProductId(), orderDTO.getQuantity());

    // 4. 扣减账户余额（RM3注册分支事务）
    accountService.reduceBalance(orderDTO.getUserId(), orderDTO.getAmount());

    // 5. TM决定全局事务的提交或回滚
    log.info("Global transaction completed");
}
```

### 4.3 Seata AT 模式

#### 4.3.1 AT 模式原理

AT（Automatic Transaction）模式是基于两阶段提交协议的演进，通过代理数据源自动生成回滚 SQL，实现自动化的分布式事务管理。

**AT 模式特点：**

-   基于支持本地 ACID 事务的关系型数据库
-   应用通过 JDBC 访问数据库
-   完全非侵入：业务代码无需修改
-   自动生成回滚操作

#### 4.3.2 AT 模式实现

```java
// AT模式配置
@Configuration
public class SeataConfiguration {

    @Bean
    @Primary
    public DataSource dataSource() {
        DruidDataSource druidDataSource = new DruidDataSource();
        druidDataSource.setUrl("jdbc:mysql://localhost:3306/seata_order");
        druidDataSource.setUsername("root");
        druidDataSource.setPassword("123456");
        return new DataSourceProxy(druidDataSource);
    }

    @Bean
    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {
        SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();
        sessionFactory.setDataSource(dataSource);
        return sessionFactory.getObject();
    }
}

// 业务服务实现
@Service
public class OrderServiceImpl implements OrderService {

    @Autowired
    private OrderMapper orderMapper;

    @Override
    public void createOrder(OrderDTO orderDTO) {
        Order order = new Order();
        order.setUserId(orderDTO.getUserId());
        order.setProductId(orderDTO.getProductId());
        order.setAmount(orderDTO.getAmount());
        order.setStatus(OrderStatus.PENDING);

        // Seata会自动拦截这个SQL操作
        // 在一阶段生成before_image和after_image
        orderMapper.insert(order);
    }
}

// 库存服务
@Service
public class InventoryServiceImpl implements InventoryService {

    @Autowired
    private InventoryMapper inventoryMapper;

    @Override
    public void reduceStock(Long productId, Integer quantity) {
        Inventory inventory = inventoryMapper.selectByProductId(productId);

        if (inventory.getStock() < quantity) {
            throw new InsufficientStockException("库存不足");
        }

        inventory.setStock(inventory.getStock() - quantity);
        // Seata会记录这次更新操作的前后镜像
        inventoryMapper.updateByProductId(inventory);
    }
}
```

#### 4.3.3 Undo_log 表结构

```sql
-- Seata AT模式需要的undo_log表
CREATE TABLE `undo_log` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `branch_id` bigint(20) NOT NULL,
    `xid` varchar(100) NOT NULL,
    `context` varchar(128) NOT NULL,
    `rollback_info` longblob NOT NULL,
    `log_status` int(11) NOT NULL,
    `log_created` datetime NOT NULL,
    `log_modified` datetime NOT NULL,
    PRIMARY KEY (`id`),
    UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

### 4.4 Seata TCC 模式

#### 4.4.1 TCC 模式原理

TCC 模式需要用户根据自己的业务场景实现 Try、Confirm、Cancel 三个操作。

```java
// TCC接口定义
@LocalTCC
public interface AccountTccAction {

    /**
     * 预扣费用
     * @param actionContext 上下文
     * @param userId 用户ID
     * @param amount 金额
     * @return 是否成功
     */
    @TwoPhaseBusinessAction(name = "accountTccAction", commitMethod = "commit", rollbackMethod = "rollback")
    boolean prepare(@BusinessActionContextParameter(paramName = "actionContext") BusinessActionContext actionContext,
                   @BusinessActionContextParameter(paramName = "userId") String userId,
                   @BusinessActionContextParameter(paramName = "amount") BigDecimal amount);

    /**
     * 确认扣费
     * @param actionContext 上下文
     * @return 是否成功
     */
    boolean commit(BusinessActionContext actionContext);

    /**
     * 取消扣费
     * @param actionContext 上下文
     * @return 是否成功
     */
    boolean rollback(BusinessActionContext actionContext);
}

// TCC实现类
@Service
public class AccountTccActionImpl implements AccountTccAction {

    @Autowired
    private AccountService accountService;

    @Override
    public boolean prepare(BusinessActionContext actionContext, String userId, BigDecimal amount) {
        // 预扣费用，冻结账户金额
        return accountService.freezeAmount(userId, amount, actionContext.getXid());
    }

    @Override
    public boolean commit(BusinessActionContext actionContext) {
        // 确认扣费，真正扣除冻结金额
        String userId = actionContext.getActionContext("userId").toString();
        BigDecimal amount = new BigDecimal(actionContext.getActionContext("amount").toString());
        return accountService.confirmDeduction(userId, amount, actionContext.getXid());
    }

    @Override
    public boolean rollback(BusinessActionContext actionContext) {
        // 取消扣费，释放冻结金额
        String userId = actionContext.getActionContext("userId").toString();
        BigDecimal amount = new BigDecimal(actionContext.getActionContext("amount").toString());
        return accountService.cancelDeduction(userId, amount, actionContext.getXid());
    }
}
```

### 4.5 Seata SAGA 模式

#### 4.5.1 SAGA 模式原理

SAGA 模式是一种长事务解决方案，通过状态机编排事务流程，每个服务提供正向操作和补偿操作。

```json
{
    "Name": "OrderSaga",
    "Comment": "订单处理状态机",
    "StartAt": "CreateOrder",
    "Version": "0.0.1",
    "States": {
        "CreateOrder": {
            "Type": "ServiceTask",
            "ServiceName": "orderService",
            "ServiceMethod": "createOrder",
            "CompensateState": "CancelOrder",
            "Next": "ReduceInventory"
        },
        "ReduceInventory": {
            "Type": "ServiceTask",
            "ServiceName": "inventoryService",
            "ServiceMethod": "reduceStock",
            "CompensateState": "RestoreInventory",
            "Next": "DeductAccount"
        },
        "DeductAccount": {
            "Type": "ServiceTask",
            "ServiceName": "accountService",
            "ServiceMethod": "deductBalance",
            "CompensateState": "RefundAccount",
            "End": true
        },
        "CancelOrder": {
            "Type": "ServiceTask",
            "ServiceName": "orderService",
            "ServiceMethod": "cancelOrder"
        },
        "RestoreInventory": {
            "Type": "ServiceTask",
            "ServiceName": "inventoryService",
            "ServiceMethod": "restoreStock"
        },
        "RefundAccount": {
            "Type": "ServiceTask",
            "ServiceName": "accountService",
            "ServiceMethod": "refundBalance"
        }
    }
}
```

### 4.6 Seata XA 模式

#### 4.6.1 XA 模式原理

XA 模式利用数据库对 XA 协议的支持，实现真正的两阶段提交。

```java
// XA模式配置
@Configuration
public class SeataXAConfiguration {

    @Bean("dataSource")
    public DataSource dataSource() {
        MysqlXADataSource mysqlXADataSource = new MysqlXADataSource();
        mysqlXADataSource.setUrl("jdbc:mysql://localhost:3306/seata_order");
        mysqlXADataSource.setUser("root");
        mysqlXADataSource.setPassword("123456");

        // 使用Seata的XA数据源代理
        return new DataSourceProxyXA(mysqlXADataSource);
    }
}

// XA模式业务代码
@Service
public class OrderXAService {

    @GlobalTransactional
    public void createOrderWithXA(OrderDTO orderDTO) {
        // XA模式下，所有的数据库操作都会参与到XA事务中
        orderService.createOrder(orderDTO);
        inventoryService.reduceStock(orderDTO.getProductId(), orderDTO.getQuantity());
        accountService.deductBalance(orderDTO.getUserId(), orderDTO.getAmount());
    }
}
```

### 4.7 Seata 模式对比

| 模式      | 一致性     | 性能 | 业务侵入 | 适用场景               |
| --------- | ---------- | ---- | -------- | ---------------------- |
| AT 模式   | 最终一致性 | 较高 | 无侵入   | 基于关系型数据库的应用 |
| TCC 模式  | 最终一致性 | 高   | 强侵入   | 对性能要求高的核心业务 |
| SAGA 模式 | 最终一致性 | 高   | 中等侵入 | 长流程、多参与方业务   |
| XA 模式   | 强一致性   | 较低 | 无侵入   | 对一致性要求极高的场景 |

# 说一下两阶段提交和三阶段提交的过程？分别有什么问题？

两阶段提交协议 2PC

1. 第一阶段（投票阶段）：

（1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应；

（2）参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志。

（3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。

2. 第二阶段（提交执行阶段）：

当协调者节点从所有参与者节点获得的相应消息都为”同意”时：

（1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求；

（2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源；

（3）参与者节点向协调者节点发送”完成”消息；

（4）协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。

两阶段提交存在的问题：

1. 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态；
2. 参与者发生故障：协调者需要给每个参与者额外指定超时机制，超时后整个事务失败；
3. 协调者发生故障：参与者会一直阻塞下去。需要额外的备机进行容错；
4. 二阶段无法解决的问题：协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

三阶段提交协议 3PC

与两阶段提交不同的是，三阶段提交有两个改动点：

1. 引入超时机制。同时在协调者和参与者中都引入超时机制；
2. 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

也就是说，除了引入超时机制之外，3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段。

1. CanCommit 阶段

3PC 的 CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应。

（1）事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。

（2）响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态。否则反馈 No。

2. PreCommit 阶段

协调者根据参与者的反应情况来决定是否可以继续事务的 PreCommit 操作。根据响应情况，有以下两种可能：

假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行。

（1）发送预提交请求：协调者向参与者发送 PreCommit 请求，并进入 Prepared 阶段。

（2）事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将 undo 和 redo 信息记录到事务日志中。

（3）响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。

假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。

（1）发送中断请求：协调者向所有参与者发送 abort 请求。
