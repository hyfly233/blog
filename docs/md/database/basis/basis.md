# 数据库基础

## 架构

### RDBMS

+ 程序实例
  + 存储管理
  + 缓存机制
  + SQL解析
  + 日志管理
  + 权限划分
  + 容灾机制
  + 索引管理
  + 所管理
+ 文件系统



## 数据库范式

第一范式：列不可分，eg:【联系人】（姓名，性别，电话），一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF；

第二范式：有主键，保证完全依赖。eg:订单明细表【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName），Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID，不符合2NF；

第三范式：无传递依赖(非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况)，eg:订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID），CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。



## 什么是反模式

范式可以避免数据冗余，减少数据库的空间，减轻维护数据完整性的麻烦。

然而，通过数据库范式化设计，将导致数据库业务涉及的表变多，并且可能需要将涉及的业务表进行多表连接查询，这样将导致性能变差，且不利于分库分表。因此，出于性能优先的考量，可能在数据库的结构中需要使用反模式的设计，即空间换取时间，采取数据冗余的方式避免表之间的关联查询。至于数据一致性问题，因为难以满足数据强一致性，一般情况下，使存储数据尽可能达到用户一致，保证系统经过一段较短的时间的自我恢复和修正，数据最终达到一致。

需要谨慎使用反模式设计数据库。一般情况下，尽可能使用范式化的数据库设计，因为范式化的数据库设计能让产品更加灵活，并且能在数据库层保持数据完整性。

有的时候，提升性能最好的方法是在同一表中保存冗余数据，如果能容许少量的脏数据，创建一张完全独立的汇总表或缓存表是非常好的方法。举个例子，设计一张“下载次数表”来缓存下载次数信息，可使在海量数据的情况下，提高查询总数信息的速度。

另外一个比较典型的场景，出于扩展性考虑，可能会使用 BLOB 和 TEXT 类型的列存储 JSON 结构的数据，这样的好处在于可以在任何时候，将新的属性添加到这个字段中，而不需要更改表结构。但是，这个设计的缺点也比较明显，就是需要获取整个字段内容进行解码来获取指定的属性，并且无法进行索引、排序、聚合等操作。因此，如果需要考虑更加复杂的使用场景，更加建议使用 MongoDB 这样的文档型数据库。

## 数据库事务

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。

(1). 事务的特征

原子性(Atomicity)：事务所包含的一系列数据库操作要么全部成功执行，要么全部回滚；

一致性(Consistency)：事务的执行不能破坏数据库数据的完整性和一致性，事务在执行之前和之后，数据库都必须处于一致性状态；

隔离性(Isolation)：并发执行的事务之间不能相互影响；

持久性(Durability)：事务一旦提交，对数据库中数据的改变是永久性的。

(2). 事务并发带来的问题

脏读：一个事务读取了另一个事务未提交的数据；

不可重复读：不可重复读的重点是修改，同样条件下两次读取结果不同，也就是说，被读取的数据可以被其它事务修改；

幻读：幻读的重点在于新增或者删除，同样条件下两次读出来的记录数不一样。

(3). 隔离级别

隔离级别决定了一个session中的事务可能对另一个session中的事务的影响。

ANSI标准定义了4个隔离级别，MySQL的InnoDB都支持，分别是：

READ UNCOMMITTED（未提交读）：最低级别的隔离，通常又称为dirty read，它允许一个事务读取另一个事务还没commit的数据，这样可能会提高性能，但是会导致脏读问题；

READ COMMITTED（提交读）：在一个事务中只允许对其它事务已经commit的记录可见，该隔离级别不能避免不可重复读问题；

REPEATABLE READ（可重复读）：在一个事务开始后，其他事务对数据库的修改在本事务中不可见，直到本事务commit或rollback。但是，其他事务的insert/delete操作对该事务是可见的，也就是说，该隔离级别并不能避免幻读问题。在一个事务中重复select的结果一样，除非本事务中update数据库。

SERIALIZABLE（可串行化）：最高级别的隔离，只允许事务串行执行。

MySQL默认的隔离级别是REPEATABLE READ。

|          | 脏读 | 不可重复读 | 幻读可能性 | 加锁读 |
| :------- | :--- | :--------- | :--------- | :----- |
| 未提交读 | YES  | YES        | YES        | NO     |
| 提交读   | NO   | YES        | YES        | NO     |
| 可重复读 | NO   | NO         | YES        | NO     |
| 可串行化 | NO   | NO         | NO         | YES    |

## 什么是存储过程？有哪些优缺点？

存储过程是事先经过编译并存储在数据库中的一段SQL语句的集合。进一步地说，存储过程是由一些T-SQL语句组成的代码块，这些T-SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。存储过程具有以下特点：

- 存储过程只在创建时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次，所以使用存储过程可提高数据库执行效率；
- 当SQL语句有变动时，可以只修改数据库中的存储过程而不必修改代码；
- 减少网络传输，在客户端调用一个存储过程当然比执行一串SQL传输的数据量要小；
- 通过存储过程能够使没有权限的用户在控制之下间接地存取数据库，从而确保数据的安全。

## 简单说一说drop、delete与truncate的区别

SQL中的drop、delete、truncate都表示删除，但是三者有一些差别：

Delete用来删除表的全部或者一部分数据行，执行delete之后，用户需要提交(commmit)或者回滚(rollback)来执行删除或者撤销删除， delete命令会触发这个表上所有的delete触发器；

Truncate删除表中的所有数据，这个操作不能回滚，也不会触发这个表上的触发器，TRUNCATE比delete更快，占用的空间更小；

Drop命令从数据库中删除表，所有的数据行，索引和权限也会被删除，所有的DML触发器也不会被触发，这个命令也不能回滚。

因此，在不再需要一张表的时候，用drop；在想删除部分数据行时候，用delete；在保留表而删除所有数据的时候用truncate。

## 什么叫视图？游标是什么？

视图是一种虚拟的表，通常是有一个表或者多个表的行或列的子集，具有和物理表相同的功能，可以对视图进行增，删，改，查等操作。特别地，对视图的修改不影响基本表。相比多表查询，它使得我们获取数据更容易。

游标是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。

在操作mysql的时候，我们知道MySQL检索操作返回一组称为结果集的行。这组返回的行都是与 SQL语句相匹配的行（零行或多行）。使用简单的 SELECT语句，例如，没有办法得到第一行、下一行或前 10行，也不存在每次一行地处理所有行的简单方法（相对于成批地处理它们）。有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。游标（cursor）是一个存储在MySQL服务器上的数据库查询，它不是一条 SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。

## 什么是触发器？

触发器是与表相关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据库端确保数据库的完整性。

## 超键、候选键、主键、外键

- 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
- 候选键：是最小超键，即没有冗余元素的超键。
- 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。
- 外键：在一个表中存在的另一个表的主键称此表的外键。

## 什么是事务？什么是锁？

- 事务：就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过 ACID 测试，即原子性，一致性，隔离性和持久性。
- 锁：在所以的 DBMS 中，锁是实现事务的关键，锁可以保证事务的完整性和并发性。与现实生活中锁一样，它可以使某些数据的拥有者，在某段时间内不能使用某些数据或数据结构。当然锁还分级别的。

## 数据库锁机制

数据库锁定机制简单来说就是数据库为了保证数据的一致性而使各种共享资源在被并发访问，访问变得有序所设计的一种规则。MySQL各存储引擎使用了三种类型（级别）的锁定机制：行级锁定，页级锁定和表级锁定。

- **表级锁定（table-level）**：表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。表级锁分为读锁和写锁。
- **页级锁定（page-level）**：页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。
- **行级锁定（row-level）**：行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。InnoDB的行级锁同样分为两种，共享锁和排他锁，同样InnoDB也引入了意向锁（表级锁）的概念，所以也就有了意向共享锁和意向排他锁，所以InnoDB实际上有四种锁，即共享锁（S）、排他锁（X）、意向共享锁（IS）、意向排他锁（IX）；

在MySQL数据库中，使用表级锁定的主要是MyISAM，Memory，CSV等一些非事务性存储引擎，而使用行级锁定的主要是Innodb存储引擎和NDBCluster存储引擎，页级锁定主要是BerkeleyDB存储引擎的锁定方式。

而意向锁的作用就是当一个事务在需要获取资源锁定的时候，如果遇到自己需要的资源已经被排他锁占用的时候，该事务可以需要锁定行的表上面添加一个合适的意向锁。如果自己需要一个共享锁，那么就在表上面添加一个意向共享锁。而如果自己需要的是某行（或者某些行）上面添加一个排他锁的话，则先在表上面添加一个意向排他锁。意向共享锁可以同时并存多个，但是意向排他锁同时只能有一个存在。

|                  | 共享锁（S） | 排他锁（X） | 意向共享锁（IS） | 意向排他锁（IX） |
| :--------------- | :---------- | :---------- | :--------------- | :--------------- |
| 共享锁（S）      | 兼容        | 冲突        | 兼容             | 冲突             |
| 排他锁（X）      | 冲突        | 冲突        | 冲突             | 冲突             |
| 意向共享锁（IS） | 兼容        | 冲突        | 兼容             | 兼容             |
| 意向排他锁（IX） | 冲突        | 冲突        | 兼容             | 兼容             |

参考地址：`http://www.cnblogs.com/ggjucheng/archive/2012/11/14/2770445.html`

## DDL、DML、DCL分别指什么

## 左连接、右连接、内连接、外连接、交叉连接、笛卡儿积



# 索引

## 索引的优点

- 大大加快数据的检索速度，这也是创建索引的最主要的原因；
- 加速表和表之间的连接；
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间；
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；

## 什么情况下设置了索引但无法使用？

- 以“%(表示任意0个或多个字符)”开头的LIKE语句，模糊匹配；
- OR语句前后没有同时使用索引；
- 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）；
- 对于多列索引，必须满足 最左匹配原则 (eg：多列索引col1、col2和col3，则 索引生效的情形包括 col1或col1，col2或col1，col2，col3)。

## 什么样的字段适合创建索引？

- 经常作查询选择的字段
- 经常作表连接的字段
- 经常出现在order by, group by, distinct 后面的字段

## 创建索引时需要注意什么？

非空字段：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；

取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；

索引字段越小越好：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。

## 索引的缺点

时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；

空间方面：索引需要占物理空间。

## 索引的分类

普通索引和唯一性索引：索引列的值的唯一性

单个索引和复合索引：索引列所包含的列数

聚簇索引与非聚簇索引：聚簇索引按照数据的物理存储进行划分的。对于一堆记录来说，使用聚集索引就是对这堆记录进行堆划分，即主要描述的是物理上的存储。正是因为这种划分方法，导致聚簇索引必须是唯一的。聚集索引可以帮助把很大的范围，迅速减小范围。但是查找该记录，就要从这个小范围中Scan了；而非聚集索引是把一个很大的范围，转换成一个小的地图，然后你需要在这个小地图中找你要寻找的信息的位置，最后通过这个位置，再去找你所需要的记录。

## 主键、自增主键、主键索引与唯一索引概念区别

主键：指字段 唯一、不为空值 的列；

主键索引：指的就是主键，主键是索引的一种，是唯一索引的特殊类型。创建主键的时候，数据库默认会为主键创建一个唯一索引；

自增主键：字段类型为数字、自增、并且是主键；

唯一索引：索引列的值必须唯一，但允许有空值。主键是唯一索引，这样说没错；但反过来说，唯一索引也是主键就错误了，因为唯一索引允许空值，主键不允许有空值，所以不能说唯一索引也是主键。

## 主键就是聚集索引吗？主键和索引有什么区别？

主键是一种特殊的唯一性索引，其可以是聚集索引，也可以是非聚集索引。

在SQLServer中，主键的创建必须依赖于索引，默认创建的是聚集索引，但也可以显式指定为非聚集索引。

InnoDB作为MySQL存储引擎时，默认按照主键进行聚集，如果没有定义主键，InnoDB会试着使用唯一的非空索引来代替。如果没有这种索引，InnoDB就会定义隐藏的主键然后在上面进行聚集。所以，对于聚集索引来说，你创建主键的时候，自动就创建了主键的聚集索引。

## 索引的底层实现原理和优化

索引是对数据库表中一个或多个列的值进行排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B_TREE及其变种。索引加速了数据访问，因为存储引擎不会再去扫描整张表得到需要的数据；相反，它从根节点开始，根节点保存了子节点的指针，存储引擎会根据指针快速寻找数据。

![数据库索引方式](https://static.bookstack.cn/projects/java_interview_manual/images/db-index-data-structure.png)

　　上图显示了一种索引方式。左边是数据库中的数据表，有col1和col2两个字段，一共有15条记录；右边是以col2列为索引列的B_TREE索引，每个节点包含索引的键值和对应数据表地址的指针，这样就可以都过B_TREE在 O(logn) 的时间复杂度内获取相应的数据，这样明显地加快了检索的速度。

在数据结构中，我们最为常见的搜索结构就是二叉搜索树和AVL树(高度平衡的二叉搜索树，为了提高二叉搜索树的效率，减少树的平均搜索长度)了。然而，无论二叉搜索树还是AVL树，当数据量比较大时，都会由于树的深度过大而造成I/O读写过于频繁，进而导致查询效率低下，因此对于索引而言，多叉树结构成为不二选择。特别地，B-Tree的各种操作能使B树保持较低的高度，从而保证高效的查找效率。

### B-Tree(平衡多路查找树)

B_TREE是一种平衡多路查找树，是一种动态查找效率很高的树形结构。B_TREE中所有结点的孩子结点的最大值称为B_TREE的阶，B_TREE的阶通常用m表示，简称为m叉树。一般来说，应该是m>=3。一颗m阶的B_TREE或是一颗空树，或者是满足下列条件的m叉树：

1)树中每个结点最多有m个孩子结点；

2)若根结点不是叶子节点，则根结点至少有2个孩子结点；

3)除根结点外，其它结点至少有(m/2的上界)个孩子结点；

结点的结构如下图所示，其中，n为结点中关键字个数，(m/2的上界)-1 <= n <= m-1；di(1<=i<=n)为该结点的n个关键字值的第i个，且di< d(i+1)；ci(0<=i<=n)为该结点孩子结点的指针，且ci所指向的节点的关键字均大于或等于di且小于d(i+1)；

![ ](https://static.bookstack.cn/projects/java_interview_manual/images/db-index-bTree-1.png)

所有的叶结点都在同一层上，并且不带信息（可以看作是外部结点或查找失败的结点，实际上这些结点不存在，指向这些结点的指针为空）。

下图是一棵4阶B_TREE，4叉树结点的孩子结点的个数范围[2,4]。其中，有2个结点有4个孩子结点，有1个结点有3个孩子结点，有5个结点有2个孩子结点。

![ ](https://static.bookstack.cn/projects/java_interview_manual/images/db-index-bTree-2.png)

B_TREE的查找类似二叉排序树的查找，所不同的是B-树每个结点上是多关键码的有序表，在到达某个结点时，先在有序表中查找，若找到，则查找成功；否则，到按照对应的指针信息指向的子树中去查找，当到达叶子结点时，则说明树中没有对应的关键码。由于B_TREE的高检索效率，B-树主要应用在文件系统和数据库中，对于存储在硬盘上的大型数据库文件，可以极大程度减少访问硬盘次数，大幅度提高数据检索效率。

### B+Tree ： InnoDB存储引擎的索引实现

B+Tree是应文件系统所需而产生的一种B_TREE树的变形树。一棵m阶的B+树和m阶的B_TREE的差异在于以下三点：

- n棵子树的结点中含有n个关键码；
- 所有的叶子结点中包含了全部关键码的信息，及指向含有这些关键码记录的指针，且叶子结点本身依关键码的大小自小而大的顺序链接；
- 非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键码。

下图为一棵3阶的B+树。通常在B+树上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点。因此可以对B+树进行两种查找运算：一种是从最小关键字起顺序查找，另一种是从根节点开始，进行随机查找。

在B+树上进行随机查找、插入和删除的过程基本上与B-树类似。只是在查找时，若非终端结点上的关键码等于给定值，并不终止，而是继续向下直到叶子结点。因此，对于B+树，不管查找成功与否，每次查找都是走了一条从根到叶子结点的路径。

![ ](https://static.bookstack.cn/projects/java_interview_manual/images/db-index-bplusTree-1.jpg)

### 为什么说B+树比B树更适合实际应用中操作系统的文件索引和数据库索引？

B+tree的磁盘读写代价更低：B+tree的内部结点并没有指向关键字具体信息的指针(红色部分)，因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多，相对来说IO读写次数也就降低了；

B+tree的查询效率更加稳定：由于内部结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引，所以，任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

数据库索引采用B+树而不是B树的主要原因：B+树只要遍历叶子节点就可以实现整棵树的遍历，而且在数据库中基于范围的查询是非常频繁的，而B树只能中序遍历所有节点，效率太低。

### 文件索引和数据库索引为什么使用B+树？

文件与数据库都是需要较大的存储，也就是说，它们都不可能全部存储在内存中，故需要存储到磁盘上。而所谓索引，则为了数据的快速定位与查找，那么索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数，因此B+树相比B树更为合适。数据库系统巧妙利用了局部性原理与磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入，而红黑树这种结构，高度明显要深的多，并且由于逻辑上很近的节点(父子)物理上可能很远，无法利用局部性。最重要的是，B+树还有一个最大的好处：方便扫库。B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持，这是数据库选用B+树的最主要原因。



# 分库分表

## 说说分库与分表设计

面对海量数据，例如，上千万甚至上亿的数据，查询一次所花费的时间会变长，甚至会造成数据库的单点压力。因此，分库与分表的目的在于，减小数据库的单库单表负担，提高查询性能，缩短查询时间。

### 分表概述

随着用户数的不断增加，以及数据量的不断增加，会使得单表压力越来越大，面对上千万甚至上亿的数据，查询一次所花费的时间会变长，如果有联合查询的情况下，甚至可能会成为很大的瓶颈。此外，MySQL 存在表锁和行锁，因此更新表数据可能会引起表锁或者行锁，这样也会导致其他操作等待，甚至死锁问题。

通过分表，可以减少数据库的单表负担，将压力分散到不同的表上，同时因为不同的表上的数据量少了，起到提高查询性能，缩短查询时间的作用，此外，可以很大的缓解表锁的问题。

分表策略可以归纳为垂直拆分和水平拆分。

垂直拆分，把表的字段进行拆分，即一张字段比较多的表拆分为多张表，这样使得行数据变小。一方面，可以减少客户端程序和数据库之间的网络传输的字节数，因为生产环境共享同一个网络带宽，随着并发查询的增多，有可能造成带宽瓶颈从而造成阻塞。另一方面，一个数据块能存放更多的数据，在查询时就会减少 I/O 次数。举个例子，假设用户表中有一个字段是家庭地址，这个字段是可选字段，在数据库操作的时候除了个人信息外，并不需要经常读取或是更改这个字段的值。在这种情况下，更建议把它拆分到另外一个表，从而提高性能。

如何设计好垂直拆分，我的建议：

- 将不常用的字段单独拆分到另外一张扩展表，例如前面讲解到的用户家庭地址，这个字段是可选字段，在数据库操作的时候除了个人信息外，并不需要经常读取或是更改这个字段的值。
- 将大文本的字段单独拆分到另外一张扩展表，例如 BLOB 和 TEXT 字符串类型的字段，以及 TINYBLOB、 MEDIUMBLOB、 LONGBLOB、 TINYTEXT、 MEDIUMTEXT、 LONGTEXT字符串类型。这样可以减少客户端程序和- 数据库之间的网络传输的字节数。
- 将不经常修改的字段放在同一张表中，将经常改变的字段放在另一张表中。举个例子，假设用户表的设计中，还存在“最后登录时间”字段，每次用户登录时会被更新。这张用户表会存在频繁的更新操作，此外，每次更新时会导致该表的查询缓存被清空。所以，可以把这个字段放到另一个表中，这样查询缓存会增加很多性能。
- 对于需要经常关联查询的字段，建议放在同一张表中。不然在联合查询的情况下，会带来数据库额外压力。
- 水平拆分，把表的行进行拆分。因为表的行数超过几百万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。水平拆分，有许多策略，例如，取模分表，时间维度分表，以及自定义 Hash 分表，例如用户 ID 维度分表等。在不同策略分表情况下，根据各自的策略写入与读取。

实际上，垂直拆分后的表依然存在单表数据量过大的问题，需要进行水平拆分。因此，实际情况中，水平拆分往往会和垂直拆分结合使用。假设，随着用户数的不断增加，用户表单表存在上千万的数据，这时可以把一张用户表的数据拆成多张用户表来存放。

常见的水平分表策略归纳起来，可以总结为随机分表和连续分表两种情况。例如，取模分表就属于随机分表，而时间维度分表则属于连续分表。

连续分表可以快速定位到表进行高效查询，大多数情况下，可以有效避免跨表查询。如果想扩展，只需要添加额外的分表就可以了，无需对其他分表的数据进行数据迁移。但是，连续分表有可能存在数据热点的问题，有些表可能会被频繁地查询从而造成较大压力，热数据的表就成为了整个库的瓶颈，而有些表可能存的是历史数据，很少需要被查询到。

随机分表是遵循规则策略进行写入与读取，而不是真正意义上的随机。通常，采用取模分表或者自定义 Hash 分表的方式进行水平拆分。随机分表的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，分表扩展需要迁移旧的数据。此外，随机分表比较容易面临跨表查询的复杂问题。

对于日志场景，可以考虑根据时间维度分表，例如年份维度分表或者月份维度分表，在日志记录表的名字中包含年份和月份的信息，例如 log_2017_01，这样可以在已经没有新增操作的历史表上做频繁地查询操作，而不会影响时间维度分表上新增操作。

对于海量用户场景，可以考虑取模分表，数据相对比较均匀，不容易出现热点和并发访问的瓶颈。

对于租户场景，可以考虑租户维度分表，不同的租户数据独立，而不应该在每张表中添加租户 ID，这是一个不错的选择。

### 分库概述

库内分表，仅仅是解决了单表数据过大的问题，但并没有把单表的数据分散到不同的物理机上，因此并不能减轻 MySQL 服务器的压力，仍然存在同一个物理机上的资源竞争和瓶颈，包括 CPU、内存、磁盘 IO、网络带宽等。

分库策略也可以归纳为垂直拆分和水平拆分。

垂直拆分，按照业务和功能划分，把数据分别放到不同的数据库中。举个例子，可以划分资讯库、百科库等。

水平拆分，把一张表的数据划分到不同的数据库，两个数据库的表结构一样。实际上，水平分库与水平分表类似，水平拆分有许多策略，例如，取模分库，自定义 Hash 分库等，在不同策略分库情况下，根据各自的策略写入与读取。举个例子，随着业务的增长，资讯库的单表数据过大，此时采取水平拆分策略，根据取模分库。

以上文字来源：[服务端指南 数据存储篇 | MySQL（08） 分库与分表设计](http://blog.720ui.com/2017/mysql_core_08_multi_db_table/)

## 分库与分表带来的分布式困境与应对之策

- 数据迁移与扩容问题
- 表关联问题
- 分页与排序问题
- 分布式事务问题
- 分布式全局唯一ID

## 选择合适的分布式主键方案

## 如何设计可以动态扩容缩容的分库分表方案？

## 用过哪些分库分表中间件，有啥优点和缺点？讲一下你了解的分库分表中间件的底层实现原理？





## 1、什么是 MyBatis？ 

答：MyBatis 是一个可以自定义 SQL、存储过程和高级映射的持久层框架。 

## 2、讲下 MyBatis 的缓存答

：MyBatis 的缓存分为一级缓存和二级缓存,一级缓存放在 session 里面,默认就有,二级缓存放在它的命名空间里,默认是不打开的,使用二级缓存属性类需要实现 Serializable 序列化接口(可用来保存对象的状态),可在它的映射文件中配置<cache/> 

 

## 3、Mybatis 是如何进行分页的？分页插件的原理是什么？答： 

 

1）Mybatis 使用 RowBounds 对象进行分页，也可以直接编写 sql 实现分页，也可以使用

Mybatis 的分页插件。 

 

2）分页插件的原理：实现 Mybatis 提供的接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql。 

 

举例：select * from student，拦截 sql 后重写为：select t.* from （select * from student）t limit 0，10 

 

## 4、简述 Mybatis 的插件运行原理，以及如何编写一个插件？答： 

 

1）Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、

Executor 这 4 种接口的插件，Mybatis 通过动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是

InvocationHandler 的 invoke()方法，当然，只会拦截那些你指定需要拦截的方法。 

 

2）实现 Mybatis 的 Interceptor 接口并复写 intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。 

 

## 5、Mybatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？答： 

 

1）Mybatis 动态 sql 可以让我们在 Xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能。 

 

2）Mybatis 提供了 9 种动态 sql 标签：

trim|where|set|foreach|if|choose|when|otherwise|bind。 

 

3）其执行原理为，使用 OGNL 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。 

 

## 6、#{}和${}的区别是什么？答： 1）#{}是预编译处理，${}是字符串替换。 

 

2）Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值； 

 

3）Mybatis 在处理${}时，就是把${}替换成变量的值。 

 

4）使用#{}可以有效的防止 SQL 注入，提高系统安全性。 

 

## 7、为什么说 Mybatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？ 

答：Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 Mybatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。 

## 8、Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么？答： 

 

1）  Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。 

 

2）  它的原理是，使用 CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。 

 

## 9、MyBatis 与 Hibernate 有哪些不同？答： 

 

1）  Mybatis 和 hibernate 不同，它不完全是一个 ORM 框架，因为 MyBatis 需要程序员自己编写 Sql 语句，不过 mybatis 可以通过 XML 或注解方式灵活配置要运行的 sql 语句，并将 java 对象和 sql 语句映射生成最终执行的 sql，最后将 sql 执行的结果再映射生成 java 对象。 

 

2）  Mybatis 学习门槛低，简单易学，程序员直接编写原生态 sql，可严格控制 sql 执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是 mybatis 无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套 sql 映射文件，工作量大。 

 

3）  Hibernate 对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件（例如需求固定的定制化软件）如果用 hibernate 开发可以节省很多代码，提高效率。但是

Hibernate 的缺点是学习门槛高，要精通门槛更高，而且怎么设计 O/R 映射，在性能和对象模型之间如何权衡，以及怎样用好 Hibernate 需要具有很强的经验和能力才行。 

 

总之，按照用户的需求在有限的资源环境下只要能做出维护性、扩展性良好的软件架构都是好架构，所以框架只有适合才是最好。 

 

## 10、MyBatis 的好处是什么？答： 

 

1）  MyBatis 把 sql 语句从 Java 源程序中独立出来，放在单独的 XML 文件中编写，给程序的维护带来了很大便利。 

 

2）  MyBatis 封装了底层 JDBC API 的调用细节，并能自动将结果集转换成 Java Bean 对象，大大简化了 Java 数据库编程的重复工作。 

 

3）  因为 MyBatis 需要程序员自己去编写 sql 语句，程序员可以结合数据库自身的特点灵活控制 sql 语句，因此能够实现比 Hibernate 等全自动 orm 框架更高的查询效率，能够完成复杂查询。 

 

## 11、简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？ 

答：Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在

Xml 映射文件中，<parameterMap>标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。<resultMap>标签会被解析为 ResultMap 对象，其每个子

元素会被解析为 ResultMapping 对象。每一个<select>、<insert>、<update>、<delete>标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。 

## 12、什么是 MyBatis 的接口绑定,有什么好处？

答：接口映射就是在 MyBatis 中任意定义接口,然后把接口里面的方法和 SQL 语句绑定,我们直接调用接口方法就可以,这样比起原来了 SqlSession 提供的方法我们可以有更加灵活的选择和设置. 

## 13、接口绑定有几种实现方式,分别是怎么实现的? 

答：接口绑定有两种实现方式,一种是通过注解绑定,就是在接口的方法上面加上

@Select@Update 等注解里面包含 Sql 语句来绑定,另外一种就是通过 xml 里面写 SQL 来绑定,在这种情况下,要指定 xml 映射文件里面的 namespace 必须为接口的全路径名. 

## 14、什么情况下用注解绑定,什么情况下用 xml 绑定？

答：当 Sql 语句比较简单时候,用注解绑定；当 SQL 语句比较复杂时候,用 xml 绑定,一般用 xml 绑定的比较多 

## 15、MyBatis 实现一对一有几种方式?具体怎么操作的？

答：有联合查询和嵌套查询,联合查询是几个表联合查询,只查询一次,通过在 resultMap 里面配置 association 节点配置一对一的类就可以完成;嵌套查询是先查一个表,根据这个表里面的结果的外键 id,去再另外一个表里面查询数据,也是通过 association 配置,但另外一个表的查询通过 select 属性配置。 

## 16、Mybatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别？ 

答：能，Mybatis 不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把 selectOne()修改为 selectList()即可；多对多查询，其实就是一对多查询，只需要把 selectOne()修改为 selectList()即可。 

 

关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。 

 

## 17、MyBatis 里面的动态 Sql 是怎么设定的?用什么语法? 

答：MyBatis 里面的动态 Sql 一般是通过 if 节点来实现,通过 OGNL 语法来实现,但是如果要写的完整,必须配合 where,trim 节点,where 节点是判断包含节点有内容就插入 where,否则不插入,trim 节点是用来判断如果动态语句是以 and 或 or 开始,那么会自动把这个 and 或者 or 取掉。 

## 18、Mybatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？答： 

 

第一种是使用<resultMap>标签，逐一定义列名和对象属性名之间的映射关系。 

 

第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，Mybatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，Mybatis 一样可以正常工作。 

 

有了列名与属性名的映射关系后，Mybatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 

 

## 19、Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？ 

答：还有很多其他的标签，<resultMap>、<parameterMap>、<sql>、<include>、

<selectKey>，加上动态 sql 的 9 个标签，

trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中<sql>为 sql 片段标签，通过<include>标签引入 sql 片段，<selectKey>为不支持自增的主键生成策略标签。 

## 20、当实体类中的属性名和表中的字段名不一样，如果将查询的结果封装到指定 pojo？答： 

 

1）通过在查询的 sql 语句中定义字段名的别名。 

 

2）通过<resultMap>来映射字段名和实体类属性名的一一对应的关系。 

 

## 21、模糊查询 like 语句该怎么写答： 

 

1）在 java 中拼接通配符，通过#{}赋值 

 

2）在 Sql 语句中拼接通配符 （不安全 会引起 Sql 注入） 

 

## 22、通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应, Dao 的工作原理，是否可以重载？ 

答：不能重载，因为通过 Dao 寻找 Xml 对应的 sql 的时候全限名+方法名的保存和寻找策略。接口工作原理为 jdk 动态代理原理，运行时会为 dao 生成 proxy，代理对象会拦截接口方法，去执行对应的 sql 返回数据。 

## 23、Mybatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？ 

答：虽然 Mybatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。 

## 24、Mybatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？答：不同的 Xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置

namespace，那么 id 不能重复；毕竟 namespace 不是必须的，只是最佳实践而已。原因就是 namespace+id 是作为 Map<String,  MappedStatement>的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。 

## 25、Mybatis 中如何执行批处理？

答：使用 BatchExecutor 完成批处理。 

## 26、Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？ 

答：Mybatis 有三种基本的 Executor 执行器，SimpleExecutor、ReuseExecutor、

BatchExecutor。1）SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。2）ReuseExecutor：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map3）BatchExecutor：完成批处理。 

## 27、Mybatis 中如何指定使用哪一种 Executor 执行器？ 

答：在 Mybatis 配置文件中，可以指定默认的 ExecutorType 执行器类型，也可以手动给

DefaultSqlSessionFactory 的创建 SqlSession 的方法传递 ExecutorType 类型参数。 

## 28、Mybatis 执行批量插入，能返回数据库主键列表吗？

答：能，JDBC 都能，Mybatis 当然也能。 

## 29、Mybatis 是否可以映射 Enum 枚举类？ 

答：Mybatis 可以映射枚举类，不单可以映射枚举类，Mybatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler，实现 TypeHandler 的 setParameter()和 getResult()接口方法。TypeHandler 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 setParameter()和 getResult()两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。 

## 30、如何获取自动生成的(主)键值？ 

答：配置文件设置 usegeneratedkeys 为 true 

## 31、在 mapper 中如何传递多个参数？答： 

 

1）直接在方法中传递参数，xml 文件用#{0} #{1}来获取 

 

2）使用 @param 注解:这样可以直接在 xml 文件中通过#{name}来获取 

 

## 32、resultType resultMap 的区别？ 

答： 

 

1）类的名字和数据库相同时，可以直接设置 resultType 参数为 Pojo 类 

 

2）若不同，需要设置 resultMap 将结果名字和 Pojo 名字进行转换 

 

## 33、使用 MyBatis 的 mapper 接口调用时有哪些要求？答： 

 

1）Mapper 接口方法名和 mapper.xml 中定义的每个 sql 的 id 相同 

 

2）Mapper 接口方法的输入参数类型和 mapper.xml 中定义的每个 sql 的 parameterType 的类型相同 

 

3）Mapper 接口方法的输出参数类型和 mapper.xml 中定义的每个 sql 的 resultType 的类型相同 

 

4）Mapper.xml 文件中的 namespace 即是 mapper 接口的类路径。 

 

## 34、Mybatis 比 IBatis 比较大的几个改进是什么？答： 

 

1）有接口绑定,包括注解绑定 sql 和 xml 绑定 Sql  

 

2）动态 sql 由原来的节点配置变成 OGNL 表达式 3）    在一对一,一对多的时候引进了

association,在一对多的时候引入了 collection 节点,不过都是在 resultMap 里面配置 

 

## 35、      IBatis 和 MyBatis 在核心处理类分别叫什么？

答：IBatis 里面的核心处理类交 SqlMapClient,MyBatis 里面的核心处理类叫做 SqlSession。 

 

## 36、      IBatis 和 MyBatis 在细节上的不同有哪些？答： 

 

1）在 sql 里面变量命名有原来的#变量# 变成了#{变量} 

 

2）原来的$变量$变成了${变量} 

 

3）原来在 sql 节点里面的 class 都换名字交 type 

 

4）原来的 queryForObject queryForList 变成了 selectOne selectList5）原来的别名设置在映射文件里面放在了核心配置文件里



------



# SQL 优化

MySQL层优化我一般遵从五个原则：

1. 减少数据访问： 设置合理的字段类型，启用压缩，通过索引访问等减少磁盘IO
2. 返回更少的数据： 只返回需要的字段和数据分页处理 减少磁盘io及网络io
3. 减少交互次数： 批量DML操作，函数存储等减少数据连接次数
4. 减少服务器CPU开销： 尽量减少数据库排序操作以及全表查询，减少cpu 内存占用
5. 利用更多资源： 使用表分区，可以增加并行操作，更大限度利用cpu资源



总结到SQL优化中，就三点:

- 最大化利用索引；
- 尽可能避免全表扫描；
- 减少无效数据的查询



## 避免索引失效

### where

**1.尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。**

可以将表达式、函数操作移动到等号右侧。

```java
-- 全表扫描
SELECT * FROM T WHERE score / 10 = 9
-- 走索引
SELECT * FROM T WHERE score = 10 * 9
```



**2. 当数据量大时，避免使用where 1 = 1 的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。**

```java
SELECT username, age, sex FROM T WHERE 1 = 1
```

优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and。



**3. 查询条件不能用 <> 或者 !=**

使用索引列作为条件进行查询时，需要避免使用<>或者!=等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替



**4. where条件仅包含复合索引非前置列**

如下：复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列"key_part1"，按照MySQL联合索引的最左匹配原则，不会走联合索引。

```java
select col1 from table where key_part 2 = 1 and key_part 3 = 2
```



**5. 隐式类型转换造成不使用索引**

如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。

```java
select col1 from table where col_varchar = 123; 
```



**6. order by 条件要与where中条件一致，否则order by不会利用索引进行排序**

```java
-- 不走age索引
SELECT * FROM t order by age;

-- 走age索引
SELECT * FROM t where age > 0 order by age;
```



对于上面的语句，数据库的处理顺序是：

- 第一步：根据where条件和统计信息生成执行计划，得到数据。
- 第二步：将得到的数据排序。当执行处理数据（order by）时，数据库会先查看第一步的执行计划，看order by 的字段是否在执行计划中利用了索引。如果是，则可以利用索引顺序而直接取得已经排好序的数据。如果不是，则重新进行排序操作。
- 第三步：返回排序后的数据。

当order by 中的字段出现在where条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作。

这个结论不仅对order by有效，对其他需要排序的操作也有效。比如group by 、union 、distinct等。



### like

**1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。**

```java
SELECT * FROM t WHERE username LIKE '%陈%'
```

优化方式：尽量在字段后面使用模糊查询

```java
SELECT * FROM t WHERE username LIKE '陈%'
```



如果需求是要在前面使用模糊查询，

- 使用MySQL内置函数 `INSTR(str,substr)` 来匹配，作用类似于 java中 的 indexOf() ，查询字符串出现的角标位置
- 使用 FullText 全文索引，用match against 检索
- 数据量较大的情况，建议引用ElasticSearch、solr，亿级数据量检索速度秒级
- 当表数据量较少（几千条儿那种），别整花里胡哨的，直接用 like '%xx%'。



### or

**1. 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描。**如下：

```java
SELECT * FROM t WHERE id = 1 OR id = 3
```

优化方式：可以用union代替or。如下

```java
SELECT * FROM t WHERE id = 1
   UNION
SELECT * FROM t WHERE id = 3
```





### in

**1. 尽量避免使用 in 和 not in，会导致引擎走全表扫描。**

```java
SELECT * FROM t WHERE id IN (2,3)
```

优化方式：如果是连续数值，可以用between代替。如下：  

```java
优化方式：如果是连续数值，可以用between代替。如下：
```

如果是子查询，可以用exists代替。

```java
-- 不走索引
select * from A where A.id in (select id from B);
-- 走索引
select * from A where exists (select * from B where B.id = A.id);
```



### null

**1. 尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描。**如下：

```java
SELECT * FROM t WHERE score IS NULL
```

优化方式：可以给字段添加默认值0，对0值进行判断。如下：

```java
SELECT * FROM t WHERE score = 0
```





### hint

**1. 正确使用hint优化语句**

MySQL中可以使用hint指定优化器在执行时选择或忽略特定的索引。一般而言，处于版本变更带来的表结构索引变化，更建议避免使用hint，而是通过Analyze table多收集统计信息。但在特定场合下，指定hint可以排除其他索引干扰而指定更优的执行计划。

1. USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例子: SELECT col1 FROM table USE INDEX (mod_time, name)...
2. IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。例子: SELECT col1 FROM table IGNORE INDEX (priority) ...
3. FORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为Hint。例子: SELECT col1 FROM table FORCE INDEX (mod_time) ...

在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。如果我们知道如何选择索引，可以使用FORCE INDEX强制查询使用指定的索引。

例如：

```java
SELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC;
```



## 二、SELECT语句其他优化

**1. 避免出现select \***

首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。

使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I/O,内存和CPU消耗。

建议提出业务实际需要的列数，将指定列名以取代select *



**2. 避免出现不确定结果的函数**

特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如now()、rand()、sysdate()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。另外不确定值的函数,产生的SQL语句无法利用query cache




**3.多表关联查询时，小表在前，大表在后。**

在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了



**4. 使用表的别名**

当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误




**5. 用where字句替换HAVING字句**

避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。

where和having的区别：where后面不能使用组函数



**6.调整Where字句中的连接顺序**

MySQL采用从左往右，自上而下的顺解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集



##  三、增删改 DML 语句优化

**1. 大批量插入数据**

如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。

方法一：

```java
insert into T values(1,2); 
insert into T values(1,3); 
insert into T values(1,4);
```



方法二：

```java
Insert into T values(1,2),(1,3),(1,4); 
```


选择后一种方法的原因有三。

- 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作；
- 在特定场景可以减少对DB连接次数
- SQL语句较短，可以减少网络传输的IO



**2. 适当使用commit**

适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下：

- 事务占用的undo数据块；
- 事务在redo log中记录的数据块；
- 释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit



**3. 避免重复查询更新的数据**

针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。

例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现：

```text
Update t1 set time = now() where col1 = 1; 
Select time from t1 where id = 1; 
```



使用变量，可以重写为以下方式：

```java
Update t1 set time = now() where col1 = 1 and @now: = now (); 
Select @now; 
```



前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多



**4.查询优先还是更新（insert、update、delete）优先**

MySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。MySQL 的默认的调度策略可用总结如下：

1）写入操作优先于读取操作。

2）对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。

3）对某张数据表的多个读取操作可以同时地进行。MySQL 提供了几个语句调节符，允许你修改它的调度策略：

- LOW_PRIORITY关键字应用于DELETE、INSERT、LOAD DATA、REPLACE和UPDATE；
- HIGH_PRIORITY关键字应用于SELECT和INSERT语句；
- DELAYED关键字应用于INSERT和REPLACE语句。


如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY写入操作永远被阻塞的情况。

SELECT 查询的HIGH_PRIORITY（高优先级）关键字也类似。它允许SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。如果希望所有支持LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么 请使用--low-priority-updates 选项来启动服务器。通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个INSERT语句的影响



##  四、查询条件优化

**1. 对于复杂的查询，可以使用中间临时表 暂存数据；**



**2. 优化 group by 语句**

默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，....;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，...;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。

因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如：

```text
SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ;
```



**3. 优化join语句**

MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。


例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成：

```java
SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo )
```


如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下：

```java
SELECT col1 FROM customerinfo 
LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID 
WHERE salesinfo.CustomerID IS NULL 
```



连接(JOIN).. 之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。



**4. 优化union查询**

MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。

高效：

```java
SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 
UNION ALL 
SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3 = 'TEST'; 
```



低效：

```sql
SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 
UNION 
SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3 = 'TEST';
```



**5.拆分复杂SQL为多个小SQL，避免大事务**

- 简单的SQL容易使用到MySQL的QUERY CACHE；
- 减少锁表时间特别是使用MyISAM存储引擎的表；
- 可以使用多核CPU。



**6. 使用truncate代替delete**

当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。

使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。



**7. 使用合理的分页方式以提高分页效率**

使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。

案例1：

```java
select * from t where thread_id = 10000 and deleted = 0 
order by gmt_create asc limit 0, 15;
```


上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销=索引IO+索引全部记录结果对应的表数据IO。因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。

适用场景：当中间结果集很小（10000行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。


案例2：

```java
select t.* from (select id from t where thread_id = 10000 and deleted = 0
order by gmt_create asc limit 0, 15) a, t 
where a.id = t.id;
```



上述例子必须满足t表主键是id列，且有覆盖索引secondary key:(thread_id, deleted, gmt_create)。通过先根据过滤条件利用覆盖索引取出主键id进行排序，再进行join操作取出其他字段。数据访问开销=索引IO+索引分页后结果（例子中是15行）对应的表数据IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。

适用场景：当查询和排序字段（即where子句和order by子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用



## 五、建表优化

1. 在表中建立索引，优先考虑where、order by使用到的字段。

2. 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。
   这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。

3. 查询数据量大的表 会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。要查询100000到100050的数据，如下：

```java
SELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* 
FROM infoTab)t WHERE t.rowid > 100000 AND t.rowid <= 100050
```



4. 用varchar/nvarchar 代替 char/nchar

尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。









# 分库分表

数据库分布式核心内容：数据切分（Sharding），以及切分后对数据的定位、整合

数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的

数据切分分为两种方式：垂直（纵向）切分和水平（横向）切分 



## 垂直（纵向）切分

垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。 

### 垂直分库 

+ 概念

  以**表**为依据，按照业务归属不同，将不同的**表**拆分到不同的**库**中

+ 结果：
  + 每个**库**的**结构**都不一样；
  + 每个**库**的**数据**也不一样，没有交集；
  + 所有**库**的**并集**是全量数据；

+ 场景

  系统绝对并发量上来了，并且可以抽象出单独的业务模块

+ 分析

  到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化



### 垂直分表 

+ 概念

  以**字段**为依据，按照字段的活跃性，将**表**中字段拆到不同的**表**（主表和扩展表）中

+ 结果：
  + 每个**表**的**结构**都不一样；
  + 每个**表**的**数据**也不一样，一般来说，每个表的**字段**至少有一列交集，一般是主键，用于关联数据；
  + 所有**表**的**并集**是全量数据；

+ 场景

  系统绝对并发量并没有上来，表的记录并不多

  但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大

  以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈

+ 分析

  可以用列表页和详情页来帮助理解

  垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO

  拆了之后，要想获得全部数据就需要关联两个表来取数据

  但记住，千万别用join，因为join不仅会增加CPU负担并且会将两个表耦合在一起（必须在一个数据库实例上）

  关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据 





## 水平（横向）切分

### 水平分库

+ 概念

  以**字段**为依据，按照一定策略（hash、range等），将一个**库**中的数据拆分到多个**库**中

+ 结果：
  + 每个**库**的**结构**都一样
  + 每个**库**的**数据**都不一样，没有交集
  + 所有**库**的**并集**是全量数据

+ 场景

  系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库

+ 分析

  库多了，io和cpu的压力自然可以成倍缓解 



### 水平分表

+ 概念

  以**字段**为依据，按照一定策略（hash、range等），将一个**表**中的数据拆分到多个**表**中

+ 结果：
  + 每个**表**的**结构**都一样；
  + 每个**表**的**数据**都不一样，没有交集；
  + 所有**表**的**并集**是全量数据；

+ 场景

  系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈 

+ 分析

  表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担  





## 分库分表工具

+ sharding-sphere：jar，前身是sharding-jdbc
+ TDDL：jar，Taobao Distribute Data Layer
+ Mycat：中间件



## 分库分表步骤

1.  根据容量（当前容量和增长量）评估分库或分表个数
2.  选key（均匀）
3.  分表规则（hash或range等）
4.  执行（一般双写）  
5.  扩容问题（尽量减少数据的移动） 



## 分库分表问题

### 1、非partition key的查询问题

基于水平分库分表，拆分策略为常用的hash法。

1. **端上**除了partition key只有一个非partition key作为条件查询
   + 映射法
   + 基因法
2. **端上**除了partition key不止一个非partition key作为条件查询
   + 映射法
   + 冗余法
3. **后台**除了partition key还有各种非partition key组合条件查询
   + NoSQL法
   + 冗余法



### 2、非partition key跨库跨表分页查询问题

基于水平分库分表，拆分策略为常用的hash法。

注：用**NoSQL法**解决（ES等）



### 3、扩容问题

基于水平分库分表，拆分策略为常用的hash法 

1. 水平扩容库（升级从库法），扩容是成倍的 
2. 水平扩容表（双写迁移法），通用方案





# 数据库事务

## 事务



## Java 中的事务

最多的就是在 Service 层的增删改方法上添加 Spring @Transactional 注解管理事务

它底层会给 Service 组件生成一个对应的 Proxy 动态代理，这样所有对 Service 组件的方法都由它对应的 Proxy 来接管。

当 Proxy 在调用对应业务方法比如 add() 时，Proxy 就会基于 AOP 的思想在调用真正的业务方法前执行 setAutoCommit(false)打开事务。

然后在业务方法执行完后执行 Commit 提交事务，当在执行业务方法的过程中发生异常时就会执行 Rollback 来回滚事务。





## 分布式事务

### 实现思路

#### 可靠消息最终一致性方案

##### 本地消息表方案

### 最大努力通知方案

##### MQ 的 ack 机制 

#### TCC 强一致性方案

TCC的 全称是：

- Try(尝试)
- Confirm(确认/提交)
- Cancel(回滚)

这个其实是用到了补偿的概念，分为了三个阶段：

- Try 阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预留。
- Confirm 阶段：这个阶段说的是在各个服务中执行实际的操作。
- Cancel 阶段：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作



跨银行转账的时候，要涉及到两个银行的分布式事务，使用 TCC 方案来实现：

- Try 阶段：先把两个银行账户中的资金给它冻结住就不让操作了。
- Confirm 阶段：执行实际的转账操作，A 银行账户的资金扣减，B 银行账户的资金增加。
- Cancel 阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如 A 银行账户如果已经扣减了，但是 B 银行账户资金增加失败了，那么就得把 A 银行账户资金给加回去。





#### 2PC

2PC 即两阶段提交协议，是将整个事务流程分为两个阶段，准备阶段（Prepare phase）、提交阶段（commit phase），2 是指两个阶段，P 是指准备阶段，C 是指提交阶段 

##### XA 方案

##### Seata 方案